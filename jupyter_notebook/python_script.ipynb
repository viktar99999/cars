{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691ba56d-62a8-4acf-b1ee-b4f4b14c57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #!/usr/bin/env python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f88b92-0ad1-47c6-8ac4-fee35a6f3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb383cea-1754-47e7-87c6-7678be8ba6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de4137b-5aa1-4e92-a8a1-c8f82d0b547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795b94fe-1a3f-4a19-ac15-a2b11c6c2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71701c1c-df5e-4aa6-8ea9-ee88319ab18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f369797e-8747-4206-b3c8-2d5f53858acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c36c1e4-bbbb-4692-9904-8e72b694142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30f18d2-be75-4de6-9064-a9b4ca8de166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641c8ed3-d3d9-4a75-a4a6-8f1fa43d6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e59307-9e06-49a4-8ae0-02f9ec54cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f60e599-c337-488e-9588-2c3a670a15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a397a8d4-5562-4ac8-93db-e179bcfb1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51903717-2916-4a0f-91e0-7056caf01fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67cc7ac3-9999-47e2-bd48-ff1eeeab0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2bebbff-ef4c-470d-b7ab-1c69a35daaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9feae8fe-096b-4e7b-bbd3-83ad9cfdcfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d600b2b-fa16-4ca5-8043-eb99179361b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x728daa1524d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d43b6457-4598-4902-89e7-1ad81603f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91421ca8-7faa-4990-bf48-105e5908d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('car.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "470c56bf-642c-4045-82ad-2d6b752ef2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c98c6745-cd7d-4e4f-8a59-2aca2298fc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>yearOfRegistration</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>kilometers</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>125000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>90000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  model  yearOfRegistration  gearbox  kilometers  brand\n",
       "0      0      2                1993        1      150000      1\n",
       "1      1      1                2011        1      125000      5\n",
       "2      2     86                2004        2      125000     30\n",
       "3      3      2                2001        1      150000      1\n",
       "4      4     39                2008        1       90000     12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fcf4859-b8bf-4574-9d41-c7fc6fb1da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show head() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efe6f5ae-9dc6-417c-8a31-b47939e38ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                 0\n",
       "model                 0\n",
       "yearOfRegistration    0\n",
       "gearbox               0\n",
       "kilometers            0\n",
       "brand                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e32db2a-183f-4a4a-a19f-eaf334f73a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show isna().sum() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dcc486d-812f-4818-aa4a-29e251cfdbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                 int64\n",
      "model                 int64\n",
      "yearOfRegistration    int64\n",
      "gearbox               int64\n",
      "kilometers            int64\n",
      "brand                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f50b08e-cb41-4d64-aa37-9ad01808accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dtypes() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49523df3-3fa1-4762-bbf4-f3218e7b11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371528 entries, 0 to 371527\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype\n",
      "---  ------              --------------   -----\n",
      " 0   index               371528 non-null  int64\n",
      " 1   model               371528 non-null  int64\n",
      " 2   yearOfRegistration  371528 non-null  int64\n",
      " 3   gearbox             371528 non-null  int64\n",
      " 4   kilometers          371528 non-null  int64\n",
      " 5   brand               371528 non-null  int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 17.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00dea474-8f52-465c-9f7a-c95c1082cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e105302-71a8-4283-b193-795fab26b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371528, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58972d3e-1752-455a-a1cb-acd46a9cc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show shape() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ae1729c-46f3-4b4e-bde0-571b93730315",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4299859-5ca9-41a7-9198-fadb0a899ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show target(Y) car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26b03259-59a5-4456-a6d0-d91c528aa174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:5]\n",
    "y = df.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9d788bc-1c5b-4493-8e91-36ab2d6e6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show target(y) car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48a2648a-4ab1-4ef9-857e-53b386999820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>yearOfRegistration</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>kilometers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  model  yearOfRegistration  gearbox  kilometers\n",
       "0      0      2                1993        1      150000\n",
       "1      1      1                2011        1      125000\n",
       "2      2     86                2004        2      125000\n",
       "3      3      2                2001        1      150000\n",
       "4      4     39                2008        1       90000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ae57cdd-18d2-4e62-ace7-3f274e893328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show head() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c4abc7c-9937-4ddf-8c17-b5ea3922f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     5\n",
      "2    30\n",
      "3     1\n",
      "4    12\n",
      "Name: brand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa8ee78e-a3eb-4adb-b055-4def823fd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show target(y) car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f568ad6-0586-4fcf-8cc8-7c72897db3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               index          model  yearOfRegistration       gearbox  \\\n",
      "count  371528.000000  371528.000000       371528.000000  371528.00000   \n",
      "mean   185763.500000      26.496985         2004.890961       1.20838   \n",
      "std    107251.039743      35.612728          113.371355       0.40615   \n",
      "min         0.000000       1.000000          400.000000       1.00000   \n",
      "25%     92881.750000       4.000000         1999.000000       1.00000   \n",
      "50%    185763.500000      12.000000         2003.000000       1.00000   \n",
      "75%    278645.250000      33.000000         2008.000000       1.00000   \n",
      "max    371527.000000     204.000000        26700.000000       2.00000   \n",
      "\n",
      "          kilometers  \n",
      "count  371528.000000  \n",
      "mean   125592.816208  \n",
      "std     40152.086660  \n",
      "min         0.000000  \n",
      "25%    125000.000000  \n",
      "50%    150000.000000  \n",
      "75%    150000.000000  \n",
      "max    150000.000000  \n"
     ]
    }
   ],
   "source": [
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea99e91b-aa77-45a7-a6ad-2430efb9b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show describe() car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10e9e6bd-6fd7-4c7e-a228-7c9690ac49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c0acdbf-9cc3-49dc-9150-acefabe7640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train =0.7, test = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee9b3d5b-8027-49c4-ba5c-a0f7b7dc0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "172586ef-42d6-4336-aba7-5f853a1b3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd6fe4c3-4011-4a49-b2e6-dffc8fb55641",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "397fe50f-4bbe-4664-afaf-170bdfe67df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b020ce89-c0fb-4f08-83bf-aaf90c833b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "101ea350-d4ce-4a69-b30d-dea0cc537a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "484f70bb-a925-45ea-bfd2-b11319245644",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a35d1c20-9da5-4208-8a24-14b62efc90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb1939b9-125d-4802-ba7d-4d3c090a5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, criterion='poisson', max_depth=14, max_features=9, n_jobs = 4, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eda9cffb-1d49-4db8-afbb-5c9440d35116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=100, criterion='poisson', max_depth=14, max_features=9, n_jobs = 4, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea8072f1-3695-48a8-9dd6-76507944e837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(criterion=&#x27;poisson&#x27;, max_depth=14, max_features=9,\n",
       "                      n_jobs=4, random_state=40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(criterion=&#x27;poisson&#x27;, max_depth=14, max_features=9,\n",
       "                      n_jobs=4, random_state=40)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(criterion='poisson', max_depth=14, max_features=9,\n",
       "                      n_jobs=4, random_state=40)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9c84a50-078c-4323-8aa6-bbd3c501d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14ed0a52-fd20-4f7d-b727-18ac5a18df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cdacb7a-8a4e-45c5-8077-dcc4d0bc1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "245d4830-6ae2-4b85-8d15-bbb9b05757f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714813674884317"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc98fc26-c8e5-4059-9d80-bf3a91d76b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "044a0c01-4a77-4186-aba9-bdaf6d5f7791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714813674884317\n"
     ]
    }
   ],
   "source": [
    "print(r2(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4ca3f05-6a5c-477e-83b7-1b4717bfeabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2eecc23a-509d-460d-a495-9a9899403dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d669bde7-a9b1-49f5-90b5-56779c0d2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c9133a2-2a99-41e5-b3d7-e7e107773c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "574e1c2a-dd7c-4b5b-a039-b0307552b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "919e5865-cc32-412e-94b0-e36f25042ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.Tensor(np.array(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44a8117c-7053-4b3f-a79c-3dc98d3fb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e00f9fe0-79f4-4006-bf96-7c3d26ff6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.Tensor(np.array(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7bf311f-ceb9-4731-b9a6-b9a519939e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_test tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0ec8256-7b60-4f37-aee0-bc0a75dff712",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.Tensor(np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f550ce40-5377-4961-8d8a-e4ea3f97eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform y_train tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "beea4caa-5d38-41c6-adea-c2b3bb5dc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tensor = torch.Tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ff3e24f-ca5a-40f0-90b5-4024e0e5af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform y_test tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01400134-58cc-4cb5-aa67-aa07dbe293ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data, n_features = X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f25a29b-13e5-43f8-9612-4ed4207875fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show shape() n_data, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d82fab1-744f-4034-8d12-2fd82f26b001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260069\n"
     ]
    }
   ],
   "source": [
    "print(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60c8ba4f-a2db-4585-bfeb-87c09f10396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show shape() n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45498073-78b8-4cbc-8416-6e9c7d09e184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5966284-777b-4251-9294-da84cf6ead2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show shape() n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea7885d6-06da-4af6-8c4f-c58b3920ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(mean, target):\n",
    "    \"\"\"function loss\"\"\"\n",
    "    return mean(F.l1_loss(input, target, reduction=\"none\") / target) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d49d70af-d9ee-421b-9e0c-0df0b9af9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"function loss\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e297ead-df69-4c25-a43e-e1ca338b4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94747784-b9ce-4694-bb68-51382cf95ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0c4b705-5144-4b59-8c4c-cbea1f420ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_func_1 = [loss_func, loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fd8ce8b-d62c-44f4-bc20-3f2d0477a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b4a4bfc-7249-460a-9282-751c91a18bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = [\"MSE\", \"LOSS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dab9ebb2-8c6a-4d2e-a35f-261f11e29731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b477509-699b-4ae9-b0e4-cd3c3e46312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(models, train_data, test_data, models_name):\n",
    "    \"\"\"function print_metrics\"\"\"\n",
    "    results = np.ones(2 * len(models), len(metrics_func_1))\n",
    "    models_name = []\n",
    "    for model in models_name:\n",
    "        models_name.extend([model + \"Train\", model + \"Test\"])\n",
    "    for row, sample in enumerate([train_data, test_data]):\n",
    "        results[row + sample * 2] = evaluate(models, metrics_func_1, sample[0], sample[1])\n",
    "        results = pd.DataFrame(results, columns=metrics_name, index=models_name)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7eb98519-5d30-4fc4-9a4a-b1fd7108003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"function print_metrics\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a19db7d4-c3dd-4bdd-b81e-5e09d96b521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = (X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "526badd5-0259-49f5-8ac7-17529c150ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "661f7bc8-5438-4169-8fbe-3fe9ab7383b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = (X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36bae2f3-89b9-4064-9e95-a2686fcda77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc01b15d-d4d4-40ba-b548-ab69be93a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_sklearn = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c07a9af5-d4e3-4cd5-a1b6-54f6c10a569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dc0b49ff-a5d1-49e0-9676-a78167d4aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_sklearn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0638299-c900-4adb-8ca2-dc9785087112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkLearn.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f837dad-b3ba-428b-beae-352620affc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = [model_lr_sklearn.predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42874540-ee5b-4fa8-a4c9-c11b3c14ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lr_sklearn.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "075faf68-8ae9-4b7d-85f9-7a47ef7b93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = [\"MSE\", \"LOSS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4dab1ad9-6a02-4c1c-bf25-e6b9a51bcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9591ca61-23e1-4fa5-ac87-96245d980db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name_1 = [\"LOSS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "108373c2-587a-4352-b073-4065de8f474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c26bdbc9-b35a-42bd-95e4-20359093a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = nn.Sequential(\n",
    "    nn.Linear(in_features=n_features,\n",
    "    out_features=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e28e5c8f-4ee1-4b31-b806-16fef1615fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "64afaf53-6910-49cc-8171-1223eabf26f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "109e9a3e-bb2f-43af-8482-15971ff837d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b50d269d-8686-405f-b1be-3fddcc772283",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name_1 = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "91bd0025-7d58-4e26-8c0b-0a6566344b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4bb090cb-f29c-452f-b1a5-d711cfc2972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = optim.SGD(params=model_lr.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8f764104-9a65-4ce4-8599-071bbd55cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6626ee4e-28e1-408e-bb33-852cf67edc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_LR = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4033a381-a34f-4131-a9e6-39c2e08a155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "064b47fd-0efe-4cc8-809c-5b050a376c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_LR = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f894b583-6a74-484c-a002-cf4803110871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6240c2c-d88b-4981-b406-bf5d788de692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [04:29<00:00,  3.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.trange(EPOCHS_LR):\n",
    "    for i in range((n_data - 1) // BATCH_SIZE_LR + 1):\n",
    "        start_i = i * BATCH_SIZE_LR\n",
    "        end_i = start_i + BATCH_SIZE_LR\n",
    "        Xb = X_train_tensor[start_i: end_i]\n",
    "        yb = y_train_tensor[start_i: end_i]\n",
    "        pred = yb\n",
    "        loss_1 = loss_func(pred, yb + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5dba0dd5-55d8-4337-9106-c049a2a01887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in tqdm.trange(EPOCHS_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe869056-0a25-4db2-b030-bd1eddeff4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.52257125e+00  3.47254308e+00 -5.16932690e-02 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " [-2.07777598e-02 -4.90998070e-01  4.66162426e-02 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " [ 1.69628100e+00  1.72970938e+00  1.00239613e-01 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " ...\n",
      " [-1.25381022e+00 -2.94226524e-01  4.66162426e-02 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " [ 5.98111607e-01 -1.81785640e-01  1.93010097e-03  1.95243271e+00\n",
      "   6.08180662e-01]\n",
      " [-1.56705472e+00 -3.78557187e-01  2.87417860e-02  1.95243271e+00\n",
      "   6.08180662e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38f0ccc3-cad4-42dd-a01b-a19b1d049621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e65ce5e4-53f5-4057-924a-a610b55e902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348986     3\n",
      "183474     4\n",
      "367615    15\n",
      "32810      5\n",
      "342339     4\n",
      "          ..\n",
      "349255     5\n",
      "109292     1\n",
      "51241      1\n",
      "249845    13\n",
      "17648      4\n",
      "Name: brand, Length: 111459, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "22d7d9e1-ea60-4e8a-8814-4b56c19f2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0188d676-e061-4873-8918-8969d4ce18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(BATCH_SIZE_LR, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cf98f228-22cc-4b21-9cf1-f562e773bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "143ca64f-ef3b-4c4f-add1-cf69072c734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1.0], [0.0], [0.0], [1.0], [1.0],\n",
    "    [1.0], [0.0], [0.0], [1.0], [1.0],\n",
    "    [1.0], [0.0], [0.0], [1.0], [1.0],\n",
    "    [1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "08ed75dd-e7f5-4228-9080-670048e18f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "544faa6d-d006-4965-a561-9eaba8138fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  1.1174485683441162\n",
      "epoch:  1  loss:  1.1109535694122314\n",
      "epoch:  2  loss:  1.104507327079773\n",
      "epoch:  3  loss:  1.0981091260910034\n",
      "epoch:  4  loss:  1.0917587280273438\n",
      "epoch:  5  loss:  1.0854555368423462\n",
      "epoch:  6  loss:  1.0791995525360107\n",
      "epoch:  7  loss:  1.0729901790618896\n",
      "epoch:  8  loss:  1.0668269395828247\n",
      "epoch:  9  loss:  1.0607097148895264\n",
      "epoch:  10  loss:  1.054638147354126\n",
      "epoch:  11  loss:  1.0486117601394653\n",
      "epoch:  12  loss:  1.0426299571990967\n",
      "epoch:  13  loss:  1.0366928577423096\n",
      "epoch:  14  loss:  1.0307998657226562\n",
      "epoch:  15  loss:  1.0249508619308472\n",
      "epoch:  16  loss:  1.019145131111145\n",
      "epoch:  17  loss:  1.0133826732635498\n",
      "epoch:  18  loss:  1.0076630115509033\n",
      "epoch:  19  loss:  1.001985788345337\n",
      "epoch:  20  loss:  0.9963504672050476\n",
      "epoch:  21  loss:  0.9907571077346802\n",
      "epoch:  22  loss:  0.9852054119110107\n",
      "epoch:  23  loss:  0.9796946048736572\n",
      "epoch:  24  loss:  0.9742246866226196\n",
      "epoch:  25  loss:  0.9687952995300293\n",
      "epoch:  26  loss:  0.9634062647819519\n",
      "epoch:  27  loss:  0.9580569267272949\n",
      "epoch:  28  loss:  0.9527472257614136\n",
      "epoch:  29  loss:  0.9474768042564392\n",
      "epoch:  30  loss:  0.9422452449798584\n",
      "epoch:  31  loss:  0.9370524883270264\n",
      "epoch:  32  loss:  0.9318979978561401\n",
      "epoch:  33  loss:  0.9267816543579102\n",
      "epoch:  34  loss:  0.9217029809951782\n",
      "epoch:  35  loss:  0.9166619777679443\n",
      "epoch:  36  loss:  0.9116579294204712\n",
      "epoch:  37  loss:  0.9066908359527588\n",
      "epoch:  38  loss:  0.9017603993415833\n",
      "epoch:  39  loss:  0.8968662023544312\n",
      "epoch:  40  loss:  0.8920081257820129\n",
      "epoch:  41  loss:  0.8871856927871704\n",
      "epoch:  42  loss:  0.8823988437652588\n",
      "epoch:  43  loss:  0.8776471614837646\n",
      "epoch:  44  loss:  0.8729304075241089\n",
      "epoch:  45  loss:  0.8682483434677124\n",
      "epoch:  46  loss:  0.8636007308959961\n",
      "epoch:  47  loss:  0.8589870929718018\n",
      "epoch:  48  loss:  0.8544073700904846\n",
      "epoch:  49  loss:  0.8498613238334656\n",
      "epoch:  50  loss:  0.845348596572876\n",
      "epoch:  51  loss:  0.8408688902854919\n",
      "epoch:  52  loss:  0.8364220261573792\n",
      "epoch:  53  loss:  0.8320077061653137\n",
      "epoch:  54  loss:  0.8276257514953613\n",
      "epoch:  55  loss:  0.8232758045196533\n",
      "epoch:  56  loss:  0.8189578056335449\n",
      "epoch:  57  loss:  0.8146712779998779\n",
      "epoch:  58  loss:  0.8104161024093628\n",
      "epoch:  59  loss:  0.8061919808387756\n",
      "epoch:  60  loss:  0.8019987344741821\n",
      "epoch:  61  loss:  0.7978360652923584\n",
      "epoch:  62  loss:  0.7937037944793701\n",
      "epoch:  63  loss:  0.7896015644073486\n",
      "epoch:  64  loss:  0.785529375076294\n",
      "epoch:  65  loss:  0.7814867496490479\n",
      "epoch:  66  loss:  0.7774735689163208\n",
      "epoch:  67  loss:  0.7734896540641785\n",
      "epoch:  68  loss:  0.769534707069397\n",
      "epoch:  69  loss:  0.7656084895133972\n",
      "epoch:  70  loss:  0.7617108821868896\n",
      "epoch:  71  loss:  0.7578415274620056\n",
      "epoch:  72  loss:  0.7540003061294556\n",
      "epoch:  73  loss:  0.7501869797706604\n",
      "epoch:  74  loss:  0.746401309967041\n",
      "epoch:  75  loss:  0.7426431179046631\n",
      "epoch:  76  loss:  0.7389122247695923\n",
      "epoch:  77  loss:  0.7352082133293152\n",
      "epoch:  78  loss:  0.7315311431884766\n",
      "epoch:  79  loss:  0.7278807163238525\n",
      "epoch:  80  loss:  0.7242565751075745\n",
      "epoch:  81  loss:  0.7206587791442871\n",
      "epoch:  82  loss:  0.717086911201477\n",
      "epoch:  83  loss:  0.71354079246521\n",
      "epoch:  84  loss:  0.7100203633308411\n",
      "epoch:  85  loss:  0.7065253257751465\n",
      "epoch:  86  loss:  0.7030555009841919\n",
      "epoch:  87  loss:  0.699610710144043\n",
      "epoch:  88  loss:  0.6961907148361206\n",
      "epoch:  89  loss:  0.6927953958511353\n",
      "epoch:  90  loss:  0.6894245743751526\n",
      "epoch:  91  loss:  0.686077892780304\n",
      "epoch:  92  loss:  0.6827553510665894\n",
      "epoch:  93  loss:  0.6794567704200745\n",
      "epoch:  94  loss:  0.6761817932128906\n",
      "epoch:  95  loss:  0.6729303002357483\n",
      "epoch:  96  loss:  0.6697022318840027\n",
      "epoch:  97  loss:  0.6664973497390747\n",
      "epoch:  98  loss:  0.6633153557777405\n",
      "epoch:  99  loss:  0.66015625\n",
      "epoch:  100  loss:  0.6570197343826294\n",
      "epoch:  101  loss:  0.6539056301116943\n",
      "epoch:  102  loss:  0.65081387758255\n",
      "epoch:  103  loss:  0.6477441787719727\n",
      "epoch:  104  loss:  0.6446964144706726\n",
      "epoch:  105  loss:  0.6416704654693604\n",
      "epoch:  106  loss:  0.6386661529541016\n",
      "epoch:  107  loss:  0.6356832981109619\n",
      "epoch:  108  loss:  0.6327216625213623\n",
      "epoch:  109  loss:  0.6297812461853027\n",
      "epoch:  110  loss:  0.6268616318702698\n",
      "epoch:  111  loss:  0.623962938785553\n",
      "epoch:  112  loss:  0.6210849285125732\n",
      "epoch:  113  loss:  0.6182272434234619\n",
      "epoch:  114  loss:  0.6153899431228638\n",
      "epoch:  115  loss:  0.6125727891921997\n",
      "epoch:  116  loss:  0.6097756624221802\n",
      "epoch:  117  loss:  0.6069983839988708\n",
      "epoch:  118  loss:  0.6042407751083374\n",
      "epoch:  119  loss:  0.6015027761459351\n",
      "epoch:  120  loss:  0.5987842082977295\n",
      "epoch:  121  loss:  0.5960848331451416\n",
      "epoch:  122  loss:  0.5934045910835266\n",
      "epoch:  123  loss:  0.5907433032989502\n",
      "epoch:  124  loss:  0.588100790977478\n",
      "epoch:  125  loss:  0.5854771137237549\n",
      "epoch:  126  loss:  0.5828717350959778\n",
      "epoch:  127  loss:  0.580284833908081\n",
      "epoch:  128  loss:  0.5777162313461304\n",
      "epoch:  129  loss:  0.5751657485961914\n",
      "epoch:  130  loss:  0.5726332068443298\n",
      "epoch:  131  loss:  0.5701185464859009\n",
      "epoch:  132  loss:  0.5676215291023254\n",
      "epoch:  133  loss:  0.5651420950889587\n",
      "epoch:  134  loss:  0.5626800656318665\n",
      "epoch:  135  loss:  0.5602354407310486\n",
      "epoch:  136  loss:  0.5578078031539917\n",
      "epoch:  137  loss:  0.5553972721099854\n",
      "epoch:  138  loss:  0.5530036687850952\n",
      "epoch:  139  loss:  0.5506268739700317\n",
      "epoch:  140  loss:  0.5482666492462158\n",
      "epoch:  141  loss:  0.5459230542182922\n",
      "epoch:  142  loss:  0.5435957908630371\n",
      "epoch:  143  loss:  0.5412847995758057\n",
      "epoch:  144  loss:  0.5389899015426636\n",
      "epoch:  145  loss:  0.5367110967636108\n",
      "epoch:  146  loss:  0.5344482064247131\n",
      "epoch:  147  loss:  0.5322010517120361\n",
      "epoch:  148  loss:  0.5299696326255798\n",
      "epoch:  149  loss:  0.5277535915374756\n",
      "epoch:  150  loss:  0.5255531668663025\n",
      "epoch:  151  loss:  0.5233679413795471\n",
      "epoch:  152  loss:  0.5211979150772095\n",
      "epoch:  153  loss:  0.5190430879592896\n",
      "epoch:  154  loss:  0.5169030427932739\n",
      "epoch:  155  loss:  0.5147779583930969\n",
      "epoch:  156  loss:  0.5126675963401794\n",
      "epoch:  157  loss:  0.5105718374252319\n",
      "epoch:  158  loss:  0.5084906220436096\n",
      "epoch:  159  loss:  0.506423830986023\n",
      "epoch:  160  loss:  0.5043712854385376\n",
      "epoch:  161  loss:  0.5023329257965088\n",
      "epoch:  162  loss:  0.5003086924552917\n",
      "epoch:  163  loss:  0.49829840660095215\n",
      "epoch:  164  loss:  0.4963019788265228\n",
      "epoch:  165  loss:  0.4943193197250366\n",
      "epoch:  166  loss:  0.4923502802848816\n",
      "epoch:  167  loss:  0.49039483070373535\n",
      "epoch:  168  loss:  0.4884527921676636\n",
      "epoch:  169  loss:  0.48652422428131104\n",
      "epoch:  170  loss:  0.4846087694168091\n",
      "epoch:  171  loss:  0.48270654678344727\n",
      "epoch:  172  loss:  0.4808173179626465\n",
      "epoch:  173  loss:  0.47894108295440674\n",
      "epoch:  174  loss:  0.4770777225494385\n",
      "epoch:  175  loss:  0.4752270579338074\n",
      "epoch:  176  loss:  0.47338902950286865\n",
      "epoch:  177  loss:  0.4715636372566223\n",
      "epoch:  178  loss:  0.46975067257881165\n",
      "epoch:  179  loss:  0.46795016527175903\n",
      "epoch:  180  loss:  0.466161847114563\n",
      "epoch:  181  loss:  0.4643857777118683\n",
      "epoch:  182  loss:  0.462621808052063\n",
      "epoch:  183  loss:  0.4608697295188904\n",
      "epoch:  184  loss:  0.4591296911239624\n",
      "epoch:  185  loss:  0.4574013948440552\n",
      "epoch:  186  loss:  0.4556849002838135\n",
      "epoch:  187  loss:  0.45398008823394775\n",
      "epoch:  188  loss:  0.4522867798805237\n",
      "epoch:  189  loss:  0.45060497522354126\n",
      "epoch:  190  loss:  0.4489346146583557\n",
      "epoch:  191  loss:  0.44727545976638794\n",
      "epoch:  192  loss:  0.4456275403499603\n",
      "epoch:  193  loss:  0.4439907670021057\n",
      "epoch:  194  loss:  0.4423651099205017\n",
      "epoch:  195  loss:  0.4407503604888916\n",
      "epoch:  196  loss:  0.4391465187072754\n",
      "epoch:  197  loss:  0.43755343556404114\n",
      "epoch:  198  loss:  0.43597114086151123\n",
      "epoch:  199  loss:  0.43439948558807373\n",
      "epoch:  200  loss:  0.4328383207321167\n",
      "epoch:  201  loss:  0.4312877058982849\n",
      "epoch:  202  loss:  0.4297475218772888\n",
      "epoch:  203  loss:  0.4282175898551941\n",
      "epoch:  204  loss:  0.4266979694366455\n",
      "epoch:  205  loss:  0.42518848180770874\n",
      "epoch:  206  loss:  0.4236891269683838\n",
      "epoch:  207  loss:  0.4221997857093811\n",
      "epoch:  208  loss:  0.42072033882141113\n",
      "epoch:  209  loss:  0.4192509055137634\n",
      "epoch:  210  loss:  0.41779112815856934\n",
      "epoch:  211  loss:  0.4163411259651184\n",
      "epoch:  212  loss:  0.4149008095264435\n",
      "epoch:  213  loss:  0.4134700298309326\n",
      "epoch:  214  loss:  0.4120487570762634\n",
      "epoch:  215  loss:  0.4106369614601135\n",
      "epoch:  216  loss:  0.4092344641685486\n",
      "epoch:  217  loss:  0.4078413248062134\n",
      "epoch:  218  loss:  0.4064573645591736\n",
      "epoch:  219  loss:  0.405082643032074\n",
      "epoch:  220  loss:  0.4037170112133026\n",
      "epoch:  221  loss:  0.40236037969589233\n",
      "epoch:  222  loss:  0.40101271867752075\n",
      "epoch:  223  loss:  0.3996738791465759\n",
      "epoch:  224  loss:  0.39834392070770264\n",
      "epoch:  225  loss:  0.3970227837562561\n",
      "epoch:  226  loss:  0.3957102596759796\n",
      "epoch:  227  loss:  0.39440637826919556\n",
      "epoch:  228  loss:  0.39311107993125916\n",
      "epoch:  229  loss:  0.39182430505752563\n",
      "epoch:  230  loss:  0.39054590463638306\n",
      "epoch:  231  loss:  0.3892759084701538\n",
      "epoch:  232  loss:  0.3880142569541931\n",
      "epoch:  233  loss:  0.3867608308792114\n",
      "epoch:  234  loss:  0.38551560044288635\n",
      "epoch:  235  loss:  0.3842785358428955\n",
      "epoch:  236  loss:  0.38304951786994934\n",
      "epoch:  237  loss:  0.3818284869194031\n",
      "epoch:  238  loss:  0.3806154131889343\n",
      "epoch:  239  loss:  0.3794102668762207\n",
      "epoch:  240  loss:  0.37821292877197266\n",
      "epoch:  241  loss:  0.3770233392715454\n",
      "epoch:  242  loss:  0.37584152817726135\n",
      "epoch:  243  loss:  0.37466737627983093\n",
      "epoch:  244  loss:  0.3735008239746094\n",
      "epoch:  245  loss:  0.3723418116569519\n",
      "epoch:  246  loss:  0.37119030952453613\n",
      "epoch:  247  loss:  0.3700461983680725\n",
      "epoch:  248  loss:  0.3689095377922058\n",
      "epoch:  249  loss:  0.3677801489830017\n",
      "epoch:  250  loss:  0.3666580319404602\n",
      "epoch:  251  loss:  0.3655432164669037\n",
      "epoch:  252  loss:  0.3644355237483978\n",
      "epoch:  253  loss:  0.36333492398262024\n",
      "epoch:  254  loss:  0.3622414469718933\n",
      "epoch:  255  loss:  0.3611549139022827\n",
      "epoch:  256  loss:  0.36007535457611084\n",
      "epoch:  257  loss:  0.3590027093887329\n",
      "epoch:  258  loss:  0.35793691873550415\n",
      "epoch:  259  loss:  0.35687798261642456\n",
      "epoch:  260  loss:  0.355825811624527\n",
      "epoch:  261  loss:  0.35478025674819946\n",
      "epoch:  262  loss:  0.35374143719673157\n",
      "epoch:  263  loss:  0.35270923376083374\n",
      "epoch:  264  loss:  0.3516835570335388\n",
      "epoch:  265  loss:  0.3506644070148468\n",
      "epoch:  266  loss:  0.3496517539024353\n",
      "epoch:  267  loss:  0.3486454486846924\n",
      "epoch:  268  loss:  0.3476455509662628\n",
      "epoch:  269  loss:  0.34665200114250183\n",
      "epoch:  270  loss:  0.34566470980644226\n",
      "epoch:  271  loss:  0.3446836471557617\n",
      "epoch:  272  loss:  0.34370875358581543\n",
      "epoch:  273  loss:  0.3427400588989258\n",
      "epoch:  274  loss:  0.3417774438858032\n",
      "epoch:  275  loss:  0.3408208191394806\n",
      "epoch:  276  loss:  0.33987027406692505\n",
      "epoch:  277  loss:  0.33892568945884705\n",
      "epoch:  278  loss:  0.3379870057106018\n",
      "epoch:  279  loss:  0.33705422282218933\n",
      "epoch:  280  loss:  0.33612722158432007\n",
      "epoch:  281  loss:  0.3352060317993164\n",
      "epoch:  282  loss:  0.33429065346717834\n",
      "epoch:  283  loss:  0.33338093757629395\n",
      "epoch:  284  loss:  0.3324768841266632\n",
      "epoch:  285  loss:  0.33157849311828613\n",
      "epoch:  286  loss:  0.33068567514419556\n",
      "epoch:  287  loss:  0.3297983705997467\n",
      "epoch:  288  loss:  0.32891660928726196\n",
      "epoch:  289  loss:  0.3280402421951294\n",
      "epoch:  290  loss:  0.32716935873031616\n",
      "epoch:  291  loss:  0.3263038694858551\n",
      "epoch:  292  loss:  0.32544371485710144\n",
      "epoch:  293  loss:  0.3245888352394104\n",
      "epoch:  294  loss:  0.32373926043510437\n",
      "epoch:  295  loss:  0.3228949308395386\n",
      "epoch:  296  loss:  0.32205578684806824\n",
      "epoch:  297  loss:  0.3212217688560486\n",
      "epoch:  298  loss:  0.3203928768634796\n",
      "epoch:  299  loss:  0.31956911087036133\n",
      "epoch:  300  loss:  0.3187503516674042\n",
      "epoch:  301  loss:  0.31793662905693054\n",
      "epoch:  302  loss:  0.31712785363197327\n",
      "epoch:  303  loss:  0.31632399559020996\n",
      "epoch:  304  loss:  0.3155251145362854\n",
      "epoch:  305  loss:  0.31473106145858765\n",
      "epoch:  306  loss:  0.3139417767524719\n",
      "epoch:  307  loss:  0.3131573796272278\n",
      "epoch:  308  loss:  0.3123776912689209\n",
      "epoch:  309  loss:  0.31160271167755127\n",
      "epoch:  310  loss:  0.31083250045776367\n",
      "epoch:  311  loss:  0.3100668787956238\n",
      "epoch:  312  loss:  0.30930593609809875\n",
      "epoch:  313  loss:  0.30854952335357666\n",
      "epoch:  314  loss:  0.30779775977134705\n",
      "epoch:  315  loss:  0.3070504665374756\n",
      "epoch:  316  loss:  0.3063076436519623\n",
      "epoch:  317  loss:  0.3055693507194519\n",
      "epoch:  318  loss:  0.3048354387283325\n",
      "epoch:  319  loss:  0.3041059374809265\n",
      "epoch:  320  loss:  0.3033807873725891\n",
      "epoch:  321  loss:  0.3026600480079651\n",
      "epoch:  322  loss:  0.3019435405731201\n",
      "epoch:  323  loss:  0.301231324672699\n",
      "epoch:  324  loss:  0.3005233407020569\n",
      "epoch:  325  loss:  0.29981961846351624\n",
      "epoch:  326  loss:  0.29912006855010986\n",
      "epoch:  327  loss:  0.2984246015548706\n",
      "epoch:  328  loss:  0.2977333068847656\n",
      "epoch:  329  loss:  0.29704612493515015\n",
      "epoch:  330  loss:  0.2963629961013794\n",
      "epoch:  331  loss:  0.295683890581131\n",
      "epoch:  332  loss:  0.2950088381767273\n",
      "epoch:  333  loss:  0.2943376898765564\n",
      "epoch:  334  loss:  0.29367056488990784\n",
      "epoch:  335  loss:  0.2930073142051697\n",
      "epoch:  336  loss:  0.2923479676246643\n",
      "epoch:  337  loss:  0.29169249534606934\n",
      "epoch:  338  loss:  0.29104089736938477\n",
      "epoch:  339  loss:  0.29039305448532104\n",
      "epoch:  340  loss:  0.28974902629852295\n",
      "epoch:  341  loss:  0.2891087532043457\n",
      "epoch:  342  loss:  0.2884722352027893\n",
      "epoch:  343  loss:  0.2878393530845642\n",
      "epoch:  344  loss:  0.28721022605895996\n",
      "epoch:  345  loss:  0.286584734916687\n",
      "epoch:  346  loss:  0.28596290946006775\n",
      "epoch:  347  loss:  0.2853446304798126\n",
      "epoch:  348  loss:  0.28472989797592163\n",
      "epoch:  349  loss:  0.28411877155303955\n",
      "epoch:  350  loss:  0.283511221408844\n",
      "epoch:  351  loss:  0.282907098531723\n",
      "epoch:  352  loss:  0.2823064923286438\n",
      "epoch:  353  loss:  0.28170931339263916\n",
      "epoch:  354  loss:  0.2811155319213867\n",
      "epoch:  355  loss:  0.28052520751953125\n",
      "epoch:  356  loss:  0.2799382209777832\n",
      "epoch:  357  loss:  0.27935463190078735\n",
      "epoch:  358  loss:  0.2787743806838989\n",
      "epoch:  359  loss:  0.27819740772247314\n",
      "epoch:  360  loss:  0.2776237726211548\n",
      "epoch:  361  loss:  0.2770533263683319\n",
      "epoch:  362  loss:  0.2764861583709717\n",
      "epoch:  363  loss:  0.2759222090244293\n",
      "epoch:  364  loss:  0.27536147832870483\n",
      "epoch:  365  loss:  0.27480387687683105\n",
      "epoch:  366  loss:  0.27424946427345276\n",
      "epoch:  367  loss:  0.2736981511116028\n",
      "epoch:  368  loss:  0.2731499671936035\n",
      "epoch:  369  loss:  0.2726048529148102\n",
      "epoch:  370  loss:  0.27206283807754517\n",
      "epoch:  371  loss:  0.2715238332748413\n",
      "epoch:  372  loss:  0.2709878385066986\n",
      "epoch:  373  loss:  0.27045488357543945\n",
      "epoch:  374  loss:  0.2699248790740967\n",
      "epoch:  375  loss:  0.2693978548049927\n",
      "epoch:  376  loss:  0.26887375116348267\n",
      "epoch:  377  loss:  0.26835256814956665\n",
      "epoch:  378  loss:  0.26783430576324463\n",
      "epoch:  379  loss:  0.26731884479522705\n",
      "epoch:  380  loss:  0.26680633425712585\n",
      "epoch:  381  loss:  0.2662966251373291\n",
      "epoch:  382  loss:  0.2657897472381592\n",
      "epoch:  383  loss:  0.2652856707572937\n",
      "epoch:  384  loss:  0.2647843658924103\n",
      "epoch:  385  loss:  0.2642858028411865\n",
      "epoch:  386  loss:  0.2637900114059448\n",
      "epoch:  387  loss:  0.2632969617843628\n",
      "epoch:  388  loss:  0.2628065347671509\n",
      "epoch:  389  loss:  0.26231884956359863\n",
      "epoch:  390  loss:  0.2618338465690613\n",
      "epoch:  391  loss:  0.26135146617889404\n",
      "epoch:  392  loss:  0.2608717083930969\n",
      "epoch:  393  loss:  0.2603945732116699\n",
      "epoch:  394  loss:  0.25992003083229065\n",
      "epoch:  395  loss:  0.2594481110572815\n",
      "epoch:  396  loss:  0.2589786946773529\n",
      "epoch:  397  loss:  0.25851181149482727\n",
      "epoch:  398  loss:  0.2580474615097046\n",
      "epoch:  399  loss:  0.25758564472198486\n",
      "epoch:  400  loss:  0.2571263015270233\n",
      "epoch:  401  loss:  0.25666940212249756\n",
      "epoch:  402  loss:  0.25621500611305237\n",
      "epoch:  403  loss:  0.25576305389404297\n",
      "epoch:  404  loss:  0.2553134858608246\n",
      "epoch:  405  loss:  0.2548663318157196\n",
      "epoch:  406  loss:  0.25442156195640564\n",
      "epoch:  407  loss:  0.2539792060852051\n",
      "epoch:  408  loss:  0.25353914499282837\n",
      "epoch:  409  loss:  0.2531014680862427\n",
      "epoch:  410  loss:  0.2526661157608032\n",
      "epoch:  411  loss:  0.25223302841186523\n",
      "epoch:  412  loss:  0.2518022656440735\n",
      "epoch:  413  loss:  0.2513737976551056\n",
      "epoch:  414  loss:  0.25094759464263916\n",
      "epoch:  415  loss:  0.2505235970020294\n",
      "epoch:  416  loss:  0.25010186433792114\n",
      "epoch:  417  loss:  0.24968233704566956\n",
      "epoch:  418  loss:  0.24926500022411346\n",
      "epoch:  419  loss:  0.24884986877441406\n",
      "epoch:  420  loss:  0.24843689799308777\n",
      "epoch:  421  loss:  0.24802610278129578\n",
      "epoch:  422  loss:  0.2476174235343933\n",
      "epoch:  423  loss:  0.24721089005470276\n",
      "epoch:  424  loss:  0.24680647253990173\n",
      "epoch:  425  loss:  0.24640417098999023\n",
      "epoch:  426  loss:  0.2460039258003235\n",
      "epoch:  427  loss:  0.24560575187206268\n",
      "epoch:  428  loss:  0.24520964920520782\n",
      "epoch:  429  loss:  0.24481560289859772\n",
      "epoch:  430  loss:  0.24442358314990997\n",
      "epoch:  431  loss:  0.244033545255661\n",
      "epoch:  432  loss:  0.2436455488204956\n",
      "epoch:  433  loss:  0.2432595193386078\n",
      "epoch:  434  loss:  0.24287548661231995\n",
      "epoch:  435  loss:  0.2424933910369873\n",
      "epoch:  436  loss:  0.24211326241493225\n",
      "epoch:  437  loss:  0.2417350709438324\n",
      "epoch:  438  loss:  0.24135880172252655\n",
      "epoch:  439  loss:  0.2409844547510147\n",
      "epoch:  440  loss:  0.2406119704246521\n",
      "epoch:  441  loss:  0.2402414232492447\n",
      "epoch:  442  loss:  0.23987272381782532\n",
      "epoch:  443  loss:  0.23950588703155518\n",
      "epoch:  444  loss:  0.23914089798927307\n",
      "epoch:  445  loss:  0.2387777417898178\n",
      "epoch:  446  loss:  0.23841643333435059\n",
      "epoch:  447  loss:  0.23805692791938782\n",
      "epoch:  448  loss:  0.2376992106437683\n",
      "epoch:  449  loss:  0.23734329640865326\n",
      "epoch:  450  loss:  0.23698914051055908\n",
      "epoch:  451  loss:  0.23663677275180817\n",
      "epoch:  452  loss:  0.23628614842891693\n",
      "epoch:  453  loss:  0.23593726754188538\n",
      "epoch:  454  loss:  0.2355901002883911\n",
      "epoch:  455  loss:  0.23524466156959534\n",
      "epoch:  456  loss:  0.23490092158317566\n",
      "epoch:  457  loss:  0.23455891013145447\n",
      "epoch:  458  loss:  0.2342185527086258\n",
      "epoch:  459  loss:  0.23387986421585083\n",
      "epoch:  460  loss:  0.23354284465312958\n",
      "epoch:  461  loss:  0.23320752382278442\n",
      "epoch:  462  loss:  0.232873797416687\n",
      "epoch:  463  loss:  0.23254172503948212\n",
      "epoch:  464  loss:  0.23221126198768616\n",
      "epoch:  465  loss:  0.23188242316246033\n",
      "epoch:  466  loss:  0.23155516386032104\n",
      "epoch:  467  loss:  0.2312295138835907\n",
      "epoch:  468  loss:  0.2309054434299469\n",
      "epoch:  469  loss:  0.23058292269706726\n",
      "epoch:  470  loss:  0.23026195168495178\n",
      "epoch:  471  loss:  0.22994251549243927\n",
      "epoch:  472  loss:  0.2296246737241745\n",
      "epoch:  473  loss:  0.2293083220720291\n",
      "epoch:  474  loss:  0.2289935201406479\n",
      "epoch:  475  loss:  0.22868019342422485\n",
      "epoch:  476  loss:  0.2283683717250824\n",
      "epoch:  477  loss:  0.22805804014205933\n",
      "epoch:  478  loss:  0.22774918377399445\n",
      "epoch:  479  loss:  0.22744181752204895\n",
      "epoch:  480  loss:  0.22713589668273926\n",
      "epoch:  481  loss:  0.22683146595954895\n",
      "epoch:  482  loss:  0.22652840614318848\n",
      "epoch:  483  loss:  0.2262268364429474\n",
      "epoch:  484  loss:  0.22592663764953613\n",
      "epoch:  485  loss:  0.22562789916992188\n",
      "epoch:  486  loss:  0.22533053159713745\n",
      "epoch:  487  loss:  0.22503459453582764\n",
      "epoch:  488  loss:  0.22473999857902527\n",
      "epoch:  489  loss:  0.22444680333137512\n",
      "epoch:  490  loss:  0.2241550087928772\n",
      "epoch:  491  loss:  0.22386455535888672\n",
      "epoch:  492  loss:  0.2235754430294037\n",
      "epoch:  493  loss:  0.2232876569032669\n",
      "epoch:  494  loss:  0.22300124168395996\n",
      "epoch:  495  loss:  0.22271610796451569\n",
      "epoch:  496  loss:  0.22243237495422363\n",
      "epoch:  497  loss:  0.22214987874031067\n",
      "epoch:  498  loss:  0.22186869382858276\n",
      "epoch:  499  loss:  0.22158882021903992\n",
      "epoch:  500  loss:  0.22131021320819855\n",
      "epoch:  501  loss:  0.22103287279605865\n",
      "epoch:  502  loss:  0.22075684368610382\n",
      "epoch:  503  loss:  0.22048205137252808\n",
      "epoch:  504  loss:  0.2202085256576538\n",
      "epoch:  505  loss:  0.21993622183799744\n",
      "epoch:  506  loss:  0.21966518461704254\n",
      "epoch:  507  loss:  0.21939535439014435\n",
      "epoch:  508  loss:  0.21912674605846405\n",
      "epoch:  509  loss:  0.21885932981967926\n",
      "epoch:  510  loss:  0.21859316527843475\n",
      "epoch:  511  loss:  0.21832820773124695\n",
      "epoch:  512  loss:  0.21806439757347107\n",
      "epoch:  513  loss:  0.2178017795085907\n",
      "epoch:  514  loss:  0.21754035353660583\n",
      "epoch:  515  loss:  0.2172800749540329\n",
      "epoch:  516  loss:  0.21702098846435547\n",
      "epoch:  517  loss:  0.21676303446292877\n",
      "epoch:  518  loss:  0.216506227850914\n",
      "epoch:  519  loss:  0.21625056862831116\n",
      "epoch:  520  loss:  0.21599604189395905\n",
      "epoch:  521  loss:  0.21574264764785767\n",
      "epoch:  522  loss:  0.21549034118652344\n",
      "epoch:  523  loss:  0.21523916721343994\n",
      "epoch:  524  loss:  0.21498912572860718\n",
      "epoch:  525  loss:  0.21474015712738037\n",
      "epoch:  526  loss:  0.21449227631092072\n",
      "epoch:  527  loss:  0.2142454832792282\n",
      "epoch:  528  loss:  0.21399976313114166\n",
      "epoch:  529  loss:  0.21375516057014465\n",
      "epoch:  530  loss:  0.21351155638694763\n",
      "epoch:  531  loss:  0.21326905488967896\n",
      "epoch:  532  loss:  0.21302756667137146\n",
      "epoch:  533  loss:  0.21278715133666992\n",
      "epoch:  534  loss:  0.21254777908325195\n",
      "epoch:  535  loss:  0.21230942010879517\n",
      "epoch:  536  loss:  0.21207208931446075\n",
      "epoch:  537  loss:  0.2118358314037323\n",
      "epoch:  538  loss:  0.21160054206848145\n",
      "epoch:  539  loss:  0.21136626601219177\n",
      "epoch:  540  loss:  0.2111329734325409\n",
      "epoch:  541  loss:  0.2109006941318512\n",
      "epoch:  542  loss:  0.21066942811012268\n",
      "epoch:  543  loss:  0.21043911576271057\n",
      "epoch:  544  loss:  0.21020978689193726\n",
      "epoch:  545  loss:  0.20998142659664154\n",
      "epoch:  546  loss:  0.20975401997566223\n",
      "epoch:  547  loss:  0.2095276117324829\n",
      "epoch:  548  loss:  0.2093021273612976\n",
      "epoch:  549  loss:  0.2090775966644287\n",
      "epoch:  550  loss:  0.20885401964187622\n",
      "epoch:  551  loss:  0.20863136649131775\n",
      "epoch:  552  loss:  0.2084096372127533\n",
      "epoch:  553  loss:  0.20818887650966644\n",
      "epoch:  554  loss:  0.20796896517276764\n",
      "epoch:  555  loss:  0.20775003731250763\n",
      "epoch:  556  loss:  0.20753198862075806\n",
      "epoch:  557  loss:  0.20731483399868011\n",
      "epoch:  558  loss:  0.207098588347435\n",
      "epoch:  559  loss:  0.2068832367658615\n",
      "epoch:  560  loss:  0.20666876435279846\n",
      "epoch:  561  loss:  0.20645520091056824\n",
      "epoch:  562  loss:  0.20624251663684845\n",
      "epoch:  563  loss:  0.20603066682815552\n",
      "epoch:  564  loss:  0.20581969618797302\n",
      "epoch:  565  loss:  0.20560958981513977\n",
      "epoch:  566  loss:  0.20540037751197815\n",
      "epoch:  567  loss:  0.205191969871521\n",
      "epoch:  568  loss:  0.2049844115972519\n",
      "epoch:  569  loss:  0.20477771759033203\n",
      "epoch:  570  loss:  0.20457184314727783\n",
      "epoch:  571  loss:  0.20436684787273407\n",
      "epoch:  572  loss:  0.20416259765625\n",
      "epoch:  573  loss:  0.20395921170711517\n",
      "epoch:  574  loss:  0.2037566602230072\n",
      "epoch:  575  loss:  0.2035548985004425\n",
      "epoch:  576  loss:  0.20335397124290466\n",
      "epoch:  577  loss:  0.2031537890434265\n",
      "epoch:  578  loss:  0.2029544711112976\n",
      "epoch:  579  loss:  0.20275592803955078\n",
      "epoch:  580  loss:  0.20255814492702484\n",
      "epoch:  581  loss:  0.20236116647720337\n",
      "epoch:  582  loss:  0.20216497778892517\n",
      "epoch:  583  loss:  0.20196956396102905\n",
      "epoch:  584  loss:  0.20177489519119263\n",
      "epoch:  585  loss:  0.20158103108406067\n",
      "epoch:  586  loss:  0.2013878971338272\n",
      "epoch:  587  loss:  0.20119553804397583\n",
      "epoch:  588  loss:  0.20100393891334534\n",
      "epoch:  589  loss:  0.20081306993961334\n",
      "epoch:  590  loss:  0.20062296092510223\n",
      "epoch:  591  loss:  0.20043358206748962\n",
      "epoch:  592  loss:  0.2002449631690979\n",
      "epoch:  593  loss:  0.2000570148229599\n",
      "epoch:  594  loss:  0.19986987113952637\n",
      "epoch:  595  loss:  0.19968341290950775\n",
      "epoch:  596  loss:  0.19949765503406525\n",
      "epoch:  597  loss:  0.19931264221668243\n",
      "epoch:  598  loss:  0.19912832975387573\n",
      "epoch:  599  loss:  0.19894474744796753\n",
      "epoch:  600  loss:  0.19876185059547424\n",
      "epoch:  601  loss:  0.19857963919639587\n",
      "epoch:  602  loss:  0.19839812815189362\n",
      "epoch:  603  loss:  0.19821733236312866\n",
      "epoch:  604  loss:  0.19803719222545624\n",
      "epoch:  605  loss:  0.19785775244235992\n",
      "epoch:  606  loss:  0.19767902791500092\n",
      "epoch:  607  loss:  0.19750091433525085\n",
      "epoch:  608  loss:  0.1973235309123993\n",
      "epoch:  609  loss:  0.19714677333831787\n",
      "epoch:  610  loss:  0.19697068631649017\n",
      "epoch:  611  loss:  0.1967952847480774\n",
      "epoch:  612  loss:  0.19662052392959595\n",
      "epoch:  613  loss:  0.19644638895988464\n",
      "epoch:  614  loss:  0.19627293944358826\n",
      "epoch:  615  loss:  0.1961001306772232\n",
      "epoch:  616  loss:  0.1959279477596283\n",
      "epoch:  617  loss:  0.1957564353942871\n",
      "epoch:  618  loss:  0.19558554887771606\n",
      "epoch:  619  loss:  0.19541528820991516\n",
      "epoch:  620  loss:  0.1952456533908844\n",
      "epoch:  621  loss:  0.19507664442062378\n",
      "epoch:  622  loss:  0.1949082612991333\n",
      "epoch:  623  loss:  0.19474050402641296\n",
      "epoch:  624  loss:  0.19457334280014038\n",
      "epoch:  625  loss:  0.19440679252147675\n",
      "epoch:  626  loss:  0.19424086809158325\n",
      "epoch:  627  loss:  0.1940755397081375\n",
      "epoch:  628  loss:  0.19391080737113953\n",
      "epoch:  629  loss:  0.1937466710805893\n",
      "epoch:  630  loss:  0.193583145737648\n",
      "epoch:  631  loss:  0.1934202015399933\n",
      "epoch:  632  loss:  0.19325783848762512\n",
      "epoch:  633  loss:  0.1930960863828659\n",
      "epoch:  634  loss:  0.19293490052223206\n",
      "epoch:  635  loss:  0.19277426600456238\n",
      "epoch:  636  loss:  0.19261424243450165\n",
      "epoch:  637  loss:  0.19245478510856628\n",
      "epoch:  638  loss:  0.19229590892791748\n",
      "epoch:  639  loss:  0.19213756918907166\n",
      "epoch:  640  loss:  0.1919798105955124\n",
      "epoch:  641  loss:  0.1918226182460785\n",
      "epoch:  642  loss:  0.19166597723960876\n",
      "epoch:  643  loss:  0.19150987267494202\n",
      "epoch:  644  loss:  0.19135433435440063\n",
      "epoch:  645  loss:  0.19119936227798462\n",
      "epoch:  646  loss:  0.19104492664337158\n",
      "epoch:  647  loss:  0.19089102745056152\n",
      "epoch:  648  loss:  0.19073764979839325\n",
      "epoch:  649  loss:  0.19058483839035034\n",
      "epoch:  650  loss:  0.19043254852294922\n",
      "epoch:  651  loss:  0.19028080999851227\n",
      "epoch:  652  loss:  0.1901295781135559\n",
      "epoch:  653  loss:  0.18997886776924133\n",
      "epoch:  654  loss:  0.18982869386672974\n",
      "epoch:  655  loss:  0.18967902660369873\n",
      "epoch:  656  loss:  0.1895298808813095\n",
      "epoch:  657  loss:  0.18938125669956207\n",
      "epoch:  658  loss:  0.18923315405845642\n",
      "epoch:  659  loss:  0.18908554315567017\n",
      "epoch:  660  loss:  0.1889384388923645\n",
      "epoch:  661  loss:  0.18879184126853943\n",
      "epoch:  662  loss:  0.18864575028419495\n",
      "epoch:  663  loss:  0.18850015103816986\n",
      "epoch:  664  loss:  0.18835507333278656\n",
      "epoch:  665  loss:  0.18821044266223907\n",
      "epoch:  666  loss:  0.18806631863117218\n",
      "epoch:  667  loss:  0.18792273104190826\n",
      "epoch:  668  loss:  0.18777957558631897\n",
      "epoch:  669  loss:  0.18763689696788788\n",
      "epoch:  670  loss:  0.18749475479125977\n",
      "epoch:  671  loss:  0.18735304474830627\n",
      "epoch:  672  loss:  0.187211811542511\n",
      "epoch:  673  loss:  0.1870710700750351\n",
      "epoch:  674  loss:  0.1869307905435562\n",
      "epoch:  675  loss:  0.18679100275039673\n",
      "epoch:  676  loss:  0.18665166199207306\n",
      "epoch:  677  loss:  0.1865127682685852\n",
      "epoch:  678  loss:  0.18637436628341675\n",
      "epoch:  679  loss:  0.1862363964319229\n",
      "epoch:  680  loss:  0.18609890341758728\n",
      "epoch:  681  loss:  0.18596184253692627\n",
      "epoch:  682  loss:  0.18582522869110107\n",
      "epoch:  683  loss:  0.18568909168243408\n",
      "epoch:  684  loss:  0.1855534017086029\n",
      "epoch:  685  loss:  0.18541815876960754\n",
      "epoch:  686  loss:  0.1852833479642868\n",
      "epoch:  687  loss:  0.18514896929264069\n",
      "epoch:  688  loss:  0.18501505255699158\n",
      "epoch:  689  loss:  0.1848815381526947\n",
      "epoch:  690  loss:  0.18474848568439484\n",
      "epoch:  691  loss:  0.1846158504486084\n",
      "epoch:  692  loss:  0.18448367714881897\n",
      "epoch:  693  loss:  0.18435190618038177\n",
      "epoch:  694  loss:  0.184220552444458\n",
      "epoch:  695  loss:  0.18408963084220886\n",
      "epoch:  696  loss:  0.18395912647247314\n",
      "epoch:  697  loss:  0.18382906913757324\n",
      "epoch:  698  loss:  0.18369939923286438\n",
      "epoch:  699  loss:  0.18357014656066895\n",
      "epoch:  700  loss:  0.18344131112098694\n",
      "epoch:  701  loss:  0.18331289291381836\n",
      "epoch:  702  loss:  0.18318487703800201\n",
      "epoch:  703  loss:  0.1830572783946991\n",
      "epoch:  704  loss:  0.1829300820827484\n",
      "epoch:  705  loss:  0.18280327320098877\n",
      "epoch:  706  loss:  0.18267688155174255\n",
      "epoch:  707  loss:  0.18255089223384857\n",
      "epoch:  708  loss:  0.18242527544498444\n",
      "epoch:  709  loss:  0.18230007588863373\n",
      "epoch:  710  loss:  0.18217526376247406\n",
      "epoch:  711  loss:  0.18205085396766663\n",
      "epoch:  712  loss:  0.18192683160305023\n",
      "epoch:  713  loss:  0.1818031668663025\n",
      "epoch:  714  loss:  0.18167991936206818\n",
      "epoch:  715  loss:  0.18155702948570251\n",
      "epoch:  716  loss:  0.18143455684185028\n",
      "epoch:  717  loss:  0.1813124418258667\n",
      "epoch:  718  loss:  0.18119069933891296\n",
      "epoch:  719  loss:  0.18106935918331146\n",
      "epoch:  720  loss:  0.18094836175441742\n",
      "epoch:  721  loss:  0.1808277666568756\n",
      "epoch:  722  loss:  0.18070752918720245\n",
      "epoch:  723  loss:  0.18058766424655914\n",
      "epoch:  724  loss:  0.1804681420326233\n",
      "epoch:  725  loss:  0.18034902215003967\n",
      "epoch:  726  loss:  0.1802302598953247\n",
      "epoch:  727  loss:  0.1801118552684784\n",
      "epoch:  728  loss:  0.17999380826950073\n",
      "epoch:  729  loss:  0.17987611889839172\n",
      "epoch:  730  loss:  0.17975878715515137\n",
      "epoch:  731  loss:  0.17964179813861847\n",
      "epoch:  732  loss:  0.17952518165111542\n",
      "epoch:  733  loss:  0.17940890789031982\n",
      "epoch:  734  loss:  0.17929300665855408\n",
      "epoch:  735  loss:  0.1791774332523346\n",
      "epoch:  736  loss:  0.17906223237514496\n",
      "epoch:  737  loss:  0.1789473295211792\n",
      "epoch:  738  loss:  0.17883281409740448\n",
      "epoch:  739  loss:  0.17871862649917603\n",
      "epoch:  740  loss:  0.17860478162765503\n",
      "epoch:  741  loss:  0.1784912794828415\n",
      "epoch:  742  loss:  0.17837810516357422\n",
      "epoch:  743  loss:  0.1782652735710144\n",
      "epoch:  744  loss:  0.17815276980400085\n",
      "epoch:  745  loss:  0.17804062366485596\n",
      "epoch:  746  loss:  0.17792880535125732\n",
      "epoch:  747  loss:  0.17781728506088257\n",
      "epoch:  748  loss:  0.17770612239837646\n",
      "epoch:  749  loss:  0.17759528756141663\n",
      "epoch:  750  loss:  0.17748475074768066\n",
      "epoch:  751  loss:  0.17737457156181335\n",
      "epoch:  752  loss:  0.17726469039916992\n",
      "epoch:  753  loss:  0.17715515196323395\n",
      "epoch:  754  loss:  0.17704592645168304\n",
      "epoch:  755  loss:  0.1769370287656784\n",
      "epoch:  756  loss:  0.17682841420173645\n",
      "epoch:  757  loss:  0.17672014236450195\n",
      "epoch:  758  loss:  0.17661215364933014\n",
      "epoch:  759  loss:  0.17650452256202698\n",
      "epoch:  760  loss:  0.1763971745967865\n",
      "epoch:  761  loss:  0.1762901246547699\n",
      "epoch:  762  loss:  0.17618340253829956\n",
      "epoch:  763  loss:  0.1760769784450531\n",
      "epoch:  764  loss:  0.1759708821773529\n",
      "epoch:  765  loss:  0.1758650839328766\n",
      "epoch:  766  loss:  0.17575955390930176\n",
      "epoch:  767  loss:  0.1756543517112732\n",
      "epoch:  768  loss:  0.1755494475364685\n",
      "epoch:  769  loss:  0.1754448413848877\n",
      "epoch:  770  loss:  0.17534056305885315\n",
      "epoch:  771  loss:  0.1752365529537201\n",
      "epoch:  772  loss:  0.17513282597064972\n",
      "epoch:  773  loss:  0.1750294268131256\n",
      "epoch:  774  loss:  0.174926295876503\n",
      "epoch:  775  loss:  0.17482346296310425\n",
      "epoch:  776  loss:  0.1747209131717682\n",
      "epoch:  777  loss:  0.174618661403656\n",
      "epoch:  778  loss:  0.1745166927576065\n",
      "epoch:  779  loss:  0.17441502213478088\n",
      "epoch:  780  loss:  0.17431360483169556\n",
      "epoch:  781  loss:  0.1742125004529953\n",
      "epoch:  782  loss:  0.17411167919635773\n",
      "epoch:  783  loss:  0.17401112616062164\n",
      "epoch:  784  loss:  0.17391085624694824\n",
      "epoch:  785  loss:  0.17381086945533752\n",
      "epoch:  786  loss:  0.1737111508846283\n",
      "epoch:  787  loss:  0.17361171543598175\n",
      "epoch:  788  loss:  0.1735125482082367\n",
      "epoch:  789  loss:  0.17341366410255432\n",
      "epoch:  790  loss:  0.17331504821777344\n",
      "epoch:  791  loss:  0.17321670055389404\n",
      "epoch:  792  loss:  0.17311865091323853\n",
      "epoch:  793  loss:  0.1730208396911621\n",
      "epoch:  794  loss:  0.17292331159114838\n",
      "epoch:  795  loss:  0.17282605171203613\n",
      "epoch:  796  loss:  0.172729030251503\n",
      "epoch:  797  loss:  0.17263229191303253\n",
      "epoch:  798  loss:  0.17253583669662476\n",
      "epoch:  799  loss:  0.17243963479995728\n",
      "epoch:  800  loss:  0.1723436713218689\n",
      "epoch:  801  loss:  0.1722479909658432\n",
      "epoch:  802  loss:  0.172152578830719\n",
      "epoch:  803  loss:  0.1720574051141739\n",
      "epoch:  804  loss:  0.17196248471736908\n",
      "epoch:  805  loss:  0.17186783254146576\n",
      "epoch:  806  loss:  0.17177343368530273\n",
      "epoch:  807  loss:  0.17167928814888\n",
      "epoch:  808  loss:  0.17158539593219757\n",
      "epoch:  809  loss:  0.17149174213409424\n",
      "epoch:  810  loss:  0.1713983565568924\n",
      "epoch:  811  loss:  0.17130522429943085\n",
      "epoch:  812  loss:  0.1712123155593872\n",
      "epoch:  813  loss:  0.17111966013908386\n",
      "epoch:  814  loss:  0.1710273027420044\n",
      "epoch:  815  loss:  0.17093512415885925\n",
      "epoch:  816  loss:  0.170843243598938\n",
      "epoch:  817  loss:  0.17075158655643463\n",
      "epoch:  818  loss:  0.17066018283367157\n",
      "epoch:  819  loss:  0.17056898772716522\n",
      "epoch:  820  loss:  0.17047806084156036\n",
      "epoch:  821  loss:  0.1703873872756958\n",
      "epoch:  822  loss:  0.17029692232608795\n",
      "epoch:  823  loss:  0.1702066957950592\n",
      "epoch:  824  loss:  0.17011672258377075\n",
      "epoch:  825  loss:  0.1700269877910614\n",
      "epoch:  826  loss:  0.16993747651576996\n",
      "epoch:  827  loss:  0.16984820365905762\n",
      "epoch:  828  loss:  0.16975916922092438\n",
      "epoch:  829  loss:  0.16967035830020905\n",
      "epoch:  830  loss:  0.169581800699234\n",
      "epoch:  831  loss:  0.1694934368133545\n",
      "epoch:  832  loss:  0.16940531134605408\n",
      "epoch:  833  loss:  0.16931743919849396\n",
      "epoch:  834  loss:  0.16922977566719055\n",
      "epoch:  835  loss:  0.16914236545562744\n",
      "epoch:  836  loss:  0.16905514895915985\n",
      "epoch:  837  loss:  0.16896815598011017\n",
      "epoch:  838  loss:  0.16888141632080078\n",
      "epoch:  839  loss:  0.1687948852777481\n",
      "epoch:  840  loss:  0.16870857775211334\n",
      "epoch:  841  loss:  0.16862249374389648\n",
      "epoch:  842  loss:  0.16853663325309753\n",
      "epoch:  843  loss:  0.1684509813785553\n",
      "epoch:  844  loss:  0.16836555302143097\n",
      "epoch:  845  loss:  0.16828036308288574\n",
      "epoch:  846  loss:  0.16819536685943604\n",
      "epoch:  847  loss:  0.16811057925224304\n",
      "epoch:  848  loss:  0.16802601516246796\n",
      "epoch:  849  loss:  0.16794168949127197\n",
      "epoch:  850  loss:  0.16785754263401031\n",
      "epoch:  851  loss:  0.16777363419532776\n",
      "epoch:  852  loss:  0.16768991947174072\n",
      "epoch:  853  loss:  0.1676064133644104\n",
      "epoch:  854  loss:  0.16752313077449799\n",
      "epoch:  855  loss:  0.16744008660316467\n",
      "epoch:  856  loss:  0.1673572063446045\n",
      "epoch:  857  loss:  0.1672745645046234\n",
      "epoch:  858  loss:  0.16719211637973785\n",
      "epoch:  859  loss:  0.1671098917722702\n",
      "epoch:  860  loss:  0.16702783107757568\n",
      "epoch:  861  loss:  0.16694600880146027\n",
      "epoch:  862  loss:  0.16686439514160156\n",
      "epoch:  863  loss:  0.16678297519683838\n",
      "epoch:  864  loss:  0.1667017638683319\n",
      "epoch:  865  loss:  0.16662073135375977\n",
      "epoch:  866  loss:  0.16653993725776672\n",
      "epoch:  867  loss:  0.16645930707454681\n",
      "epoch:  868  loss:  0.1663789004087448\n",
      "epoch:  869  loss:  0.16629868745803833\n",
      "epoch:  870  loss:  0.16621866822242737\n",
      "epoch:  871  loss:  0.16613882780075073\n",
      "epoch:  872  loss:  0.166059210896492\n",
      "epoch:  873  loss:  0.16597980260849\n",
      "epoch:  874  loss:  0.1659005731344223\n",
      "epoch:  875  loss:  0.16582153737545013\n",
      "epoch:  876  loss:  0.1657426953315735\n",
      "epoch:  877  loss:  0.16566407680511475\n",
      "epoch:  878  loss:  0.16558560729026794\n",
      "epoch:  879  loss:  0.16550734639167786\n",
      "epoch:  880  loss:  0.1654292792081833\n",
      "epoch:  881  loss:  0.16535139083862305\n",
      "epoch:  882  loss:  0.16527371108531952\n",
      "epoch:  883  loss:  0.1651962250471115\n",
      "epoch:  884  loss:  0.16511890292167664\n",
      "epoch:  885  loss:  0.16504177451133728\n",
      "epoch:  886  loss:  0.16496485471725464\n",
      "epoch:  887  loss:  0.16488808393478394\n",
      "epoch:  888  loss:  0.16481152176856995\n",
      "epoch:  889  loss:  0.16473516821861267\n",
      "epoch:  890  loss:  0.16465896368026733\n",
      "epoch:  891  loss:  0.16458295285701752\n",
      "epoch:  892  loss:  0.16450712084770203\n",
      "epoch:  893  loss:  0.16443148255348206\n",
      "epoch:  894  loss:  0.1643560230731964\n",
      "epoch:  895  loss:  0.1642807424068451\n",
      "epoch:  896  loss:  0.1642056256532669\n",
      "epoch:  897  loss:  0.16413071751594543\n",
      "epoch:  898  loss:  0.1640559732913971\n",
      "epoch:  899  loss:  0.16398140788078308\n",
      "epoch:  900  loss:  0.1639070361852646\n",
      "epoch:  901  loss:  0.16383281350135803\n",
      "epoch:  902  loss:  0.163758784532547\n",
      "epoch:  903  loss:  0.1636849343776703\n",
      "epoch:  904  loss:  0.1636112630367279\n",
      "epoch:  905  loss:  0.16353775560855865\n",
      "epoch:  906  loss:  0.16346442699432373\n",
      "epoch:  907  loss:  0.16339126229286194\n",
      "epoch:  908  loss:  0.16331827640533447\n",
      "epoch:  909  loss:  0.16324546933174133\n",
      "epoch:  910  loss:  0.16317284107208252\n",
      "epoch:  911  loss:  0.16310037672519684\n",
      "epoch:  912  loss:  0.1630280762910843\n",
      "epoch:  913  loss:  0.16295595467090607\n",
      "epoch:  914  loss:  0.16288399696350098\n",
      "epoch:  915  loss:  0.16281220316886902\n",
      "epoch:  916  loss:  0.16274060308933258\n",
      "epoch:  917  loss:  0.1626691371202469\n",
      "epoch:  918  loss:  0.1625978648662567\n",
      "epoch:  919  loss:  0.16252675652503967\n",
      "epoch:  920  loss:  0.16245579719543457\n",
      "epoch:  921  loss:  0.1623850017786026\n",
      "epoch:  922  loss:  0.16231440007686615\n",
      "epoch:  923  loss:  0.16224393248558044\n",
      "epoch:  924  loss:  0.16217365860939026\n",
      "epoch:  925  loss:  0.162103533744812\n",
      "epoch:  926  loss:  0.1620335578918457\n",
      "epoch:  927  loss:  0.16196376085281372\n",
      "epoch:  928  loss:  0.16189412772655487\n",
      "epoch:  929  loss:  0.16182462871074677\n",
      "epoch:  930  loss:  0.16175532341003418\n",
      "epoch:  931  loss:  0.16168616712093353\n",
      "epoch:  932  loss:  0.16161715984344482\n",
      "epoch:  933  loss:  0.16154831647872925\n",
      "epoch:  934  loss:  0.1614796221256256\n",
      "epoch:  935  loss:  0.1614111065864563\n",
      "epoch:  936  loss:  0.16134274005889893\n",
      "epoch:  937  loss:  0.16127453744411469\n",
      "epoch:  938  loss:  0.16120648384094238\n",
      "epoch:  939  loss:  0.1611385941505432\n",
      "epoch:  940  loss:  0.16107085347175598\n",
      "epoch:  941  loss:  0.1610032618045807\n",
      "epoch:  942  loss:  0.16093583405017853\n",
      "epoch:  943  loss:  0.1608685553073883\n",
      "epoch:  944  loss:  0.16080142557621002\n",
      "epoch:  945  loss:  0.16073445975780487\n",
      "epoch:  946  loss:  0.16066762804985046\n",
      "epoch:  947  loss:  0.160600945353508\n",
      "epoch:  948  loss:  0.16053444147109985\n",
      "epoch:  949  loss:  0.16046808660030365\n",
      "epoch:  950  loss:  0.160401850938797\n",
      "epoch:  951  loss:  0.16033577919006348\n",
      "epoch:  952  loss:  0.16026988625526428\n",
      "epoch:  953  loss:  0.16020411252975464\n",
      "epoch:  954  loss:  0.16013848781585693\n",
      "epoch:  955  loss:  0.16007302701473236\n",
      "epoch:  956  loss:  0.16000771522521973\n",
      "epoch:  957  loss:  0.15994253754615784\n",
      "epoch:  958  loss:  0.1598774790763855\n",
      "epoch:  959  loss:  0.15981261432170868\n",
      "epoch:  960  loss:  0.1597478687763214\n",
      "epoch:  961  loss:  0.15968328714370728\n",
      "epoch:  962  loss:  0.15961885452270508\n",
      "epoch:  963  loss:  0.15955452620983124\n",
      "epoch:  964  loss:  0.15949037671089172\n",
      "epoch:  965  loss:  0.15942634642124176\n",
      "epoch:  966  loss:  0.15936246514320374\n",
      "epoch:  967  loss:  0.15929874777793884\n",
      "epoch:  968  loss:  0.1592351496219635\n",
      "epoch:  969  loss:  0.1591717004776001\n",
      "epoch:  970  loss:  0.15910838544368744\n",
      "epoch:  971  loss:  0.15904520452022552\n",
      "epoch:  972  loss:  0.15898218750953674\n",
      "epoch:  973  loss:  0.1589193046092987\n",
      "epoch:  974  loss:  0.15885654091835022\n",
      "epoch:  975  loss:  0.15879394114017487\n",
      "epoch:  976  loss:  0.15873146057128906\n",
      "epoch:  977  loss:  0.158669114112854\n",
      "epoch:  978  loss:  0.15860694646835327\n",
      "epoch:  979  loss:  0.1585448831319809\n",
      "epoch:  980  loss:  0.15848296880722046\n",
      "epoch:  981  loss:  0.15842117369174957\n",
      "epoch:  982  loss:  0.15835952758789062\n",
      "epoch:  983  loss:  0.15829801559448242\n",
      "epoch:  984  loss:  0.15823663771152496\n",
      "epoch:  985  loss:  0.15817540884017944\n",
      "epoch:  986  loss:  0.15811428427696228\n",
      "epoch:  987  loss:  0.15805330872535706\n",
      "epoch:  988  loss:  0.15799249708652496\n",
      "epoch:  989  loss:  0.15793177485466003\n",
      "epoch:  990  loss:  0.15787120163440704\n",
      "epoch:  991  loss:  0.1578107476234436\n",
      "epoch:  992  loss:  0.1577504426240921\n",
      "epoch:  993  loss:  0.15769027173519135\n",
      "epoch:  994  loss:  0.15763020515441895\n",
      "epoch:  995  loss:  0.15757030248641968\n",
      "epoch:  996  loss:  0.15751050412654877\n",
      "epoch:  997  loss:  0.1574508547782898\n",
      "epoch:  998  loss:  0.15739133954048157\n",
      "epoch:  999  loss:  0.1573319137096405\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    y_pred = model_lr(X)\n",
    "    loss = metrics_name_1(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    Optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    Optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ff24db3-3935-462f-be53-43197690de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76b8fe5a-0a52-42d8-a43e-8ee0ad943417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_lr, loss_fn, optimizer):\n",
    "    \"\"\"function train\"\"\"\n",
    "    size = len(X_train_tensor)\n",
    "    model_lr.train()\n",
    "    for batch_size_lr in range(1000):\n",
    "        y_pred_1 = model_lr(X)\n",
    "        loss = loss_fn(y_pred_1, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if BATCH_SIZE_LR % 16 == 0:\n",
    "            loss_2 = loss.item(), BATCH_SIZE_LR * len(X)\n",
    "            print(f'loss: {loss_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b01f9e55-2197-483a-a92c-191d6229904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"function train\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a37ed0ab-3f04-465b-aeb8-68e149e324c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_lr, loss_fn):\n",
    "    \"\"\"function test\"\"\"\n",
    "    size = len(X_train_tensor)\n",
    "    num_batches = size\n",
    "    model_lr.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_size_lr in range(1000):\n",
    "            y_pred_2 = model_lr(X)\n",
    "            test_loss += loss_fn(y_pred_2, y).item()\n",
    "            test_loss /= num_batches\n",
    "            print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0181d63-0262-42af-99ad-ad1acf848afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"function test\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e67be97f-e207-4499-9b61-52ec2fa5ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "acca5b52-15cb-42a8-b733-303595e4573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eb42efad-ed1a-4c61-adb4-c2eac3175227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a8526fd7-ef70-4b6f-8177-42246f0c41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google-chrome-stable 119 -error memory chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ddf1ccd-e5e2-405c-984d-1959adf6d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results(for epoch in range(EPOCHS_LR)): to see python_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a5147749-cf1c-421f-90f5-73f47e5f4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8761]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model_lr(X_test_tensor[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "138c5b6b-4dcf-447e-9fdb-df8f7bd91b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_tensor[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4290edc1-daa4-4ee0-9949-cf744adc6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_lr, \"lr.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6437d463-6db3-4f0d-add3-160abdbdcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f334ec61-15a8-475f-85f8-aea3f33df616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_1 = nn.Sequential(\n",
    "    nn.Linear(in_features=n_features, out_features=16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=16, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=32, out_features=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f7673fd5-c771-4360-bf50-f16e17764ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch model_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bb0829b1-6224-4229-945b-ed35e3d91292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aeb65b66-bf17-4157-ba23-d70e46220ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch model_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "229437b4-fcf7-46c5-8348-fa3a405eb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name_2 = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a4cd7d3e-bd4c-4ec8-b6e3-3c9f7e8abd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bed35aac-e00b-421b-96f3-c04ae92d1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = optim.SGD(params=model_lr_1.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6495e661-e996-42d5-945b-65e78b53b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim model_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f9a08fe-9512-41bf-b706-225c91499b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_LR_1 = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bbb296b7-fdb3-4ba9-99b5-fe1ae338c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "af8bf58f-2747-4677-9d3e-689944d48ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_LR_1 = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d478a5f8-26e1-4000-a0f8-96b9cc4cf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c6a484c3-2658-4036-b97b-9b218174b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [04:28<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.trange(EPOCHS_LR_1):\n",
    "    for i in range((n_data - 1) // BATCH_SIZE_LR_1 + 1):\n",
    "        start_i = i * BATCH_SIZE_LR_1\n",
    "        end_i = start_i + BATCH_SIZE_LR_1\n",
    "        Xb = X_train_tensor[start_i: end_i]\n",
    "        yb = y_train_tensor[start_i: end_i]\n",
    "        pred_2 = yb\n",
    "        loss = loss_func(pred_2, yb + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ca2fce49-7aec-4f0f-afcb-fa98fba17ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in tqdm.trange(EPOCHS_LR_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f680ffd7-ab83-4795-ad23-7ec8618beeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.52257125e+00  3.47254308e+00 -5.16932690e-02 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " [-2.07777598e-02 -4.90998070e-01  4.66162426e-02 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " [ 1.69628100e+00  1.72970938e+00  1.00239613e-01 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " ...\n",
      " [-1.25381022e+00 -2.94226524e-01  4.66162426e-02 -5.12181544e-01\n",
      "   6.08180662e-01]\n",
      " [ 5.98111607e-01 -1.81785640e-01  1.93010097e-03  1.95243271e+00\n",
      "   6.08180662e-01]\n",
      " [-1.56705472e+00 -3.78557187e-01  2.87417860e-02  1.95243271e+00\n",
      "   6.08180662e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0e8fc935-6fea-41f5-be4b-af57449517b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "41311665-2509-4352-9de4-96ea4828c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348986     3\n",
      "183474     4\n",
      "367615    15\n",
      "32810      5\n",
      "342339     4\n",
      "          ..\n",
      "349255     5\n",
      "109292     1\n",
      "51241      1\n",
      "249845    13\n",
      "17648      4\n",
      "Name: brand, Length: 111459, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9aef30fa-7692-40fe-a921-04585a8aa557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2ca1b67a-ada8-40a7-863d-4471ad52249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(BATCH_SIZE_LR_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5c0b7041-68e8-4b67-bbd0-5a0d3c756d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b915c908-f164-474d-9089-1c4882ab518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1.0], [0.0], [0.0], [1.0], [1.0],\n",
    "    [1.0], [0.0], [0.0], [1.0], [1.0],\n",
    "    [1.0], [0.0], [0.0], [1.0], [1.0],\n",
    "    [1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c46ff3e8-7ad8-4b61-a89f-4e2b039c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2d27d59e-300f-4464-9e3b-cab8e16f485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  0.6988736987113953\n",
      "epoch:  1  loss:  0.6985899209976196\n",
      "epoch:  2  loss:  0.6983062624931335\n",
      "epoch:  3  loss:  0.698022723197937\n",
      "epoch:  4  loss:  0.6977393627166748\n",
      "epoch:  5  loss:  0.6974562406539917\n",
      "epoch:  6  loss:  0.6971732378005981\n",
      "epoch:  7  loss:  0.6968903541564941\n",
      "epoch:  8  loss:  0.6966078281402588\n",
      "epoch:  9  loss:  0.6963252425193787\n",
      "epoch:  10  loss:  0.6960429549217224\n",
      "epoch:  11  loss:  0.6957607865333557\n",
      "epoch:  12  loss:  0.6954788565635681\n",
      "epoch:  13  loss:  0.6951969265937805\n",
      "epoch:  14  loss:  0.6949151754379272\n",
      "epoch:  15  loss:  0.6946336030960083\n",
      "epoch:  16  loss:  0.6943522095680237\n",
      "epoch:  17  loss:  0.6940709948539734\n",
      "epoch:  18  loss:  0.6937899589538574\n",
      "epoch:  19  loss:  0.6935089826583862\n",
      "epoch:  20  loss:  0.6932281851768494\n",
      "epoch:  21  loss:  0.6929476857185364\n",
      "epoch:  22  loss:  0.6926672458648682\n",
      "epoch:  23  loss:  0.6923869848251343\n",
      "epoch:  24  loss:  0.6921068429946899\n",
      "epoch:  25  loss:  0.6918269395828247\n",
      "epoch:  26  loss:  0.6915472149848938\n",
      "epoch:  27  loss:  0.6912676095962524\n",
      "epoch:  28  loss:  0.6909880638122559\n",
      "epoch:  29  loss:  0.6907088160514832\n",
      "epoch:  30  loss:  0.6904296875\n",
      "epoch:  31  loss:  0.6901507377624512\n",
      "epoch:  32  loss:  0.6898719072341919\n",
      "epoch:  33  loss:  0.6895933151245117\n",
      "epoch:  34  loss:  0.6893148422241211\n",
      "epoch:  35  loss:  0.6890364289283752\n",
      "epoch:  36  loss:  0.6887582540512085\n",
      "epoch:  37  loss:  0.6884803771972656\n",
      "epoch:  38  loss:  0.6882025599479675\n",
      "epoch:  39  loss:  0.687924861907959\n",
      "epoch:  40  loss:  0.68764728307724\n",
      "epoch:  41  loss:  0.6873700022697449\n",
      "epoch:  42  loss:  0.6870928406715393\n",
      "epoch:  43  loss:  0.6868158578872681\n",
      "epoch:  44  loss:  0.6865389347076416\n",
      "epoch:  45  loss:  0.6862621307373047\n",
      "epoch:  46  loss:  0.6859855055809021\n",
      "epoch:  47  loss:  0.6857090592384338\n",
      "epoch:  48  loss:  0.6854326725006104\n",
      "epoch:  49  loss:  0.6851565837860107\n",
      "epoch:  50  loss:  0.6848805546760559\n",
      "epoch:  51  loss:  0.6846047639846802\n",
      "epoch:  52  loss:  0.6843290328979492\n",
      "epoch:  53  loss:  0.6840535998344421\n",
      "epoch:  54  loss:  0.6837782263755798\n",
      "epoch:  55  loss:  0.6835029721260071\n",
      "epoch:  56  loss:  0.6832280158996582\n",
      "epoch:  57  loss:  0.6829530596733093\n",
      "epoch:  58  loss:  0.6826784014701843\n",
      "epoch:  59  loss:  0.6824038028717041\n",
      "epoch:  60  loss:  0.682129442691803\n",
      "epoch:  61  loss:  0.6818548440933228\n",
      "epoch:  62  loss:  0.6815804243087769\n",
      "epoch:  63  loss:  0.6813062429428101\n",
      "epoch:  64  loss:  0.6810321807861328\n",
      "epoch:  65  loss:  0.6807581186294556\n",
      "epoch:  66  loss:  0.6804842948913574\n",
      "epoch:  67  loss:  0.6802106499671936\n",
      "epoch:  68  loss:  0.6799372434616089\n",
      "epoch:  69  loss:  0.679663896560669\n",
      "epoch:  70  loss:  0.6793906688690186\n",
      "epoch:  71  loss:  0.679117739200592\n",
      "epoch:  72  loss:  0.6788449287414551\n",
      "epoch:  73  loss:  0.6785722374916077\n",
      "epoch:  74  loss:  0.6782997846603394\n",
      "epoch:  75  loss:  0.678027331829071\n",
      "epoch:  76  loss:  0.6777552366256714\n",
      "epoch:  77  loss:  0.677483081817627\n",
      "epoch:  78  loss:  0.6772111654281616\n",
      "epoch:  79  loss:  0.6769394874572754\n",
      "epoch:  80  loss:  0.6766679883003235\n",
      "epoch:  81  loss:  0.6763965487480164\n",
      "epoch:  82  loss:  0.6761253476142883\n",
      "epoch:  83  loss:  0.6758542656898499\n",
      "epoch:  84  loss:  0.6755833029747009\n",
      "epoch:  85  loss:  0.6753125786781311\n",
      "epoch:  86  loss:  0.6750418543815613\n",
      "epoch:  87  loss:  0.6747714281082153\n",
      "epoch:  88  loss:  0.6745011806488037\n",
      "epoch:  89  loss:  0.6742309927940369\n",
      "epoch:  90  loss:  0.6739611029624939\n",
      "epoch:  91  loss:  0.6736912131309509\n",
      "epoch:  92  loss:  0.6734215617179871\n",
      "epoch:  93  loss:  0.6731520891189575\n",
      "epoch:  94  loss:  0.6728826761245728\n",
      "epoch:  95  loss:  0.6726135015487671\n",
      "epoch:  96  loss:  0.6723445057868958\n",
      "epoch:  97  loss:  0.6720755696296692\n",
      "epoch:  98  loss:  0.6718068718910217\n",
      "epoch:  99  loss:  0.6715382933616638\n",
      "epoch:  100  loss:  0.6712698340415955\n",
      "epoch:  101  loss:  0.6710016131401062\n",
      "epoch:  102  loss:  0.6707335710525513\n",
      "epoch:  103  loss:  0.6704655289649963\n",
      "epoch:  104  loss:  0.6701980829238892\n",
      "epoch:  105  loss:  0.6699315905570984\n",
      "epoch:  106  loss:  0.6696653366088867\n",
      "epoch:  107  loss:  0.6693991422653198\n",
      "epoch:  108  loss:  0.6691331267356873\n",
      "epoch:  109  loss:  0.6688674092292786\n",
      "epoch:  110  loss:  0.6686017513275146\n",
      "epoch:  111  loss:  0.6683362126350403\n",
      "epoch:  112  loss:  0.6680708527565002\n",
      "epoch:  113  loss:  0.6678056120872498\n",
      "epoch:  114  loss:  0.6675405502319336\n",
      "epoch:  115  loss:  0.6672756671905518\n",
      "epoch:  116  loss:  0.6670109033584595\n",
      "epoch:  117  loss:  0.6667463779449463\n",
      "epoch:  118  loss:  0.6664819121360779\n",
      "epoch:  119  loss:  0.6662176847457886\n",
      "epoch:  120  loss:  0.665953516960144\n",
      "epoch:  121  loss:  0.6656895875930786\n",
      "epoch:  122  loss:  0.665425717830658\n",
      "epoch:  123  loss:  0.6651620268821716\n",
      "epoch:  124  loss:  0.6648985147476196\n",
      "epoch:  125  loss:  0.664635181427002\n",
      "epoch:  126  loss:  0.6643719673156738\n",
      "epoch:  127  loss:  0.6641089916229248\n",
      "epoch:  128  loss:  0.6638461351394653\n",
      "epoch:  129  loss:  0.6635833978652954\n",
      "epoch:  130  loss:  0.6633208990097046\n",
      "epoch:  131  loss:  0.6630584597587585\n",
      "epoch:  132  loss:  0.662796139717102\n",
      "epoch:  133  loss:  0.6625341176986694\n",
      "epoch:  134  loss:  0.6622722148895264\n",
      "epoch:  135  loss:  0.6620103120803833\n",
      "epoch:  136  loss:  0.6617487072944641\n",
      "epoch:  137  loss:  0.6614872217178345\n",
      "epoch:  138  loss:  0.6612259149551392\n",
      "epoch:  139  loss:  0.6609646081924438\n",
      "epoch:  140  loss:  0.6607034802436829\n",
      "epoch:  141  loss:  0.6604421138763428\n",
      "epoch:  142  loss:  0.660180926322937\n",
      "epoch:  143  loss:  0.6599198579788208\n",
      "epoch:  144  loss:  0.6596589088439941\n",
      "epoch:  145  loss:  0.6593982577323914\n",
      "epoch:  146  loss:  0.6591375470161438\n",
      "epoch:  147  loss:  0.6588771343231201\n",
      "epoch:  148  loss:  0.6586169004440308\n",
      "epoch:  149  loss:  0.6583567261695862\n",
      "epoch:  150  loss:  0.6580966711044312\n",
      "epoch:  151  loss:  0.6578367948532104\n",
      "epoch:  152  loss:  0.6575771570205688\n",
      "epoch:  153  loss:  0.6573176383972168\n",
      "epoch:  154  loss:  0.6570582389831543\n",
      "epoch:  155  loss:  0.6567990183830261\n",
      "epoch:  156  loss:  0.6565399169921875\n",
      "epoch:  157  loss:  0.6562811136245728\n",
      "epoch:  158  loss:  0.6560235023498535\n",
      "epoch:  159  loss:  0.655765950679779\n",
      "epoch:  160  loss:  0.6555086374282837\n",
      "epoch:  161  loss:  0.6552513837814331\n",
      "epoch:  162  loss:  0.6549942493438721\n",
      "epoch:  163  loss:  0.6547373533248901\n",
      "epoch:  164  loss:  0.6544805765151978\n",
      "epoch:  165  loss:  0.6542240381240845\n",
      "epoch:  166  loss:  0.6539674997329712\n",
      "epoch:  167  loss:  0.6537111401557922\n",
      "epoch:  168  loss:  0.6534550786018372\n",
      "epoch:  169  loss:  0.6531989574432373\n",
      "epoch:  170  loss:  0.6529430747032166\n",
      "epoch:  171  loss:  0.6526873707771301\n",
      "epoch:  172  loss:  0.6524317860603333\n",
      "epoch:  173  loss:  0.6521763801574707\n",
      "epoch:  174  loss:  0.6519210338592529\n",
      "epoch:  175  loss:  0.6516659259796143\n",
      "epoch:  176  loss:  0.6514109373092651\n",
      "epoch:  177  loss:  0.6511561274528503\n",
      "epoch:  178  loss:  0.6509014368057251\n",
      "epoch:  179  loss:  0.6506469249725342\n",
      "epoch:  180  loss:  0.650392472743988\n",
      "epoch:  181  loss:  0.6501381993293762\n",
      "epoch:  182  loss:  0.6498841047286987\n",
      "epoch:  183  loss:  0.6496301293373108\n",
      "epoch:  184  loss:  0.6493763327598572\n",
      "epoch:  185  loss:  0.6491227149963379\n",
      "epoch:  186  loss:  0.6488691568374634\n",
      "epoch:  187  loss:  0.648615837097168\n",
      "epoch:  188  loss:  0.6483626365661621\n",
      "epoch:  189  loss:  0.648109495639801\n",
      "epoch:  190  loss:  0.647856593132019\n",
      "epoch:  191  loss:  0.6476038694381714\n",
      "epoch:  192  loss:  0.6473512053489685\n",
      "epoch:  193  loss:  0.6470987200737\n",
      "epoch:  194  loss:  0.646846354007721\n",
      "epoch:  195  loss:  0.6465941667556763\n",
      "epoch:  196  loss:  0.6463419198989868\n",
      "epoch:  197  loss:  0.6460889577865601\n",
      "epoch:  198  loss:  0.6458361148834229\n",
      "epoch:  199  loss:  0.64558345079422\n",
      "epoch:  200  loss:  0.6453309059143066\n",
      "epoch:  201  loss:  0.6450785994529724\n",
      "epoch:  202  loss:  0.6448262929916382\n",
      "epoch:  203  loss:  0.6445742249488831\n",
      "epoch:  204  loss:  0.6443223357200623\n",
      "epoch:  205  loss:  0.6440705060958862\n",
      "epoch:  206  loss:  0.6438188552856445\n",
      "epoch:  207  loss:  0.6435674428939819\n",
      "epoch:  208  loss:  0.6433160305023193\n",
      "epoch:  209  loss:  0.6430647969245911\n",
      "epoch:  210  loss:  0.6428136825561523\n",
      "epoch:  211  loss:  0.6425628662109375\n",
      "epoch:  212  loss:  0.6423121094703674\n",
      "epoch:  213  loss:  0.6420614123344421\n",
      "epoch:  214  loss:  0.6418108940124512\n",
      "epoch:  215  loss:  0.6415605545043945\n",
      "epoch:  216  loss:  0.6413103342056274\n",
      "epoch:  217  loss:  0.6410602927207947\n",
      "epoch:  218  loss:  0.6408103704452515\n",
      "epoch:  219  loss:  0.6405605673789978\n",
      "epoch:  220  loss:  0.6403110027313232\n",
      "epoch:  221  loss:  0.6400614976882935\n",
      "epoch:  222  loss:  0.6398121118545532\n",
      "epoch:  223  loss:  0.6395630836486816\n",
      "epoch:  224  loss:  0.6393139362335205\n",
      "epoch:  225  loss:  0.6390650272369385\n",
      "epoch:  226  loss:  0.6388162970542908\n",
      "epoch:  227  loss:  0.6385676264762878\n",
      "epoch:  228  loss:  0.6383193135261536\n",
      "epoch:  229  loss:  0.6380708813667297\n",
      "epoch:  230  loss:  0.6378227472305298\n",
      "epoch:  231  loss:  0.6375746726989746\n",
      "epoch:  232  loss:  0.6373268365859985\n",
      "epoch:  233  loss:  0.637079119682312\n",
      "epoch:  234  loss:  0.6368314623832703\n",
      "epoch:  235  loss:  0.6365840435028076\n",
      "epoch:  236  loss:  0.6363367438316345\n",
      "epoch:  237  loss:  0.6360896229743958\n",
      "epoch:  238  loss:  0.6358426809310913\n",
      "epoch:  239  loss:  0.6355957984924316\n",
      "epoch:  240  loss:  0.6353490352630615\n",
      "epoch:  241  loss:  0.6351024508476257\n",
      "epoch:  242  loss:  0.6348559856414795\n",
      "epoch:  243  loss:  0.6346096992492676\n",
      "epoch:  244  loss:  0.6343635320663452\n",
      "epoch:  245  loss:  0.6341174840927124\n",
      "epoch:  246  loss:  0.6338716745376587\n",
      "epoch:  247  loss:  0.633625864982605\n",
      "epoch:  248  loss:  0.6333803534507751\n",
      "epoch:  249  loss:  0.6331349015235901\n",
      "epoch:  250  loss:  0.6328895688056946\n",
      "epoch:  251  loss:  0.6326444745063782\n",
      "epoch:  252  loss:  0.6323994398117065\n",
      "epoch:  253  loss:  0.6321545839309692\n",
      "epoch:  254  loss:  0.6319098472595215\n",
      "epoch:  255  loss:  0.6316652894020081\n",
      "epoch:  256  loss:  0.6314208507537842\n",
      "epoch:  257  loss:  0.6311765909194946\n",
      "epoch:  258  loss:  0.6309325098991394\n",
      "epoch:  259  loss:  0.6306884288787842\n",
      "epoch:  260  loss:  0.6304445862770081\n",
      "epoch:  261  loss:  0.6302007436752319\n",
      "epoch:  262  loss:  0.6299571990966797\n",
      "epoch:  263  loss:  0.6297137141227722\n",
      "epoch:  264  loss:  0.6294704675674438\n",
      "epoch:  265  loss:  0.6292272806167603\n",
      "epoch:  266  loss:  0.6289843320846558\n",
      "epoch:  267  loss:  0.6287413835525513\n",
      "epoch:  268  loss:  0.6284987330436707\n",
      "epoch:  269  loss:  0.6282562017440796\n",
      "epoch:  270  loss:  0.6280136704444885\n",
      "epoch:  271  loss:  0.6277713775634766\n",
      "epoch:  272  loss:  0.6275291442871094\n",
      "epoch:  273  loss:  0.6272871494293213\n",
      "epoch:  274  loss:  0.6270452737808228\n",
      "epoch:  275  loss:  0.6268035173416138\n",
      "epoch:  276  loss:  0.6265618801116943\n",
      "epoch:  277  loss:  0.626320481300354\n",
      "epoch:  278  loss:  0.6260791420936584\n",
      "epoch:  279  loss:  0.6258379220962524\n",
      "epoch:  280  loss:  0.6255969405174255\n",
      "epoch:  281  loss:  0.6253560185432434\n",
      "epoch:  282  loss:  0.6251152753829956\n",
      "epoch:  283  loss:  0.6248746514320374\n",
      "epoch:  284  loss:  0.6246341466903687\n",
      "epoch:  285  loss:  0.6243938207626343\n",
      "epoch:  286  loss:  0.6241535544395447\n",
      "epoch:  287  loss:  0.6239135265350342\n",
      "epoch:  288  loss:  0.6236735582351685\n",
      "epoch:  289  loss:  0.6234337687492371\n",
      "epoch:  290  loss:  0.62319415807724\n",
      "epoch:  291  loss:  0.6229546070098877\n",
      "epoch:  292  loss:  0.6227152347564697\n",
      "epoch:  293  loss:  0.6224760413169861\n",
      "epoch:  294  loss:  0.6222370266914368\n",
      "epoch:  295  loss:  0.6219980120658875\n",
      "epoch:  296  loss:  0.6217592358589172\n",
      "epoch:  297  loss:  0.6215205192565918\n",
      "epoch:  298  loss:  0.6212820410728455\n",
      "epoch:  299  loss:  0.6210436224937439\n",
      "epoch:  300  loss:  0.6208053827285767\n",
      "epoch:  301  loss:  0.6205672025680542\n",
      "epoch:  302  loss:  0.6203292608261108\n",
      "epoch:  303  loss:  0.6200913190841675\n",
      "epoch:  304  loss:  0.619853675365448\n",
      "epoch:  305  loss:  0.6196161508560181\n",
      "epoch:  306  loss:  0.6193786859512329\n",
      "epoch:  307  loss:  0.6191413402557373\n",
      "epoch:  308  loss:  0.6189042329788208\n",
      "epoch:  309  loss:  0.6186672449111938\n",
      "epoch:  310  loss:  0.6184303164482117\n",
      "epoch:  311  loss:  0.6181935667991638\n",
      "epoch:  312  loss:  0.6179569959640503\n",
      "epoch:  313  loss:  0.6177205443382263\n",
      "epoch:  314  loss:  0.6174842715263367\n",
      "epoch:  315  loss:  0.6172480583190918\n",
      "epoch:  316  loss:  0.6170119643211365\n",
      "epoch:  317  loss:  0.6167760491371155\n",
      "epoch:  318  loss:  0.616540253162384\n",
      "epoch:  319  loss:  0.6163046360015869\n",
      "epoch:  320  loss:  0.6160691380500793\n",
      "epoch:  321  loss:  0.6158337593078613\n",
      "epoch:  322  loss:  0.6155984997749329\n",
      "epoch:  323  loss:  0.6153634190559387\n",
      "epoch:  324  loss:  0.6151285171508789\n",
      "epoch:  325  loss:  0.6148936748504639\n",
      "epoch:  326  loss:  0.6146589517593384\n",
      "epoch:  327  loss:  0.614424467086792\n",
      "epoch:  328  loss:  0.614190936088562\n",
      "epoch:  329  loss:  0.6139575839042664\n",
      "epoch:  330  loss:  0.6137243509292603\n",
      "epoch:  331  loss:  0.6134912967681885\n",
      "epoch:  332  loss:  0.6132583618164062\n",
      "epoch:  333  loss:  0.6130255460739136\n",
      "epoch:  334  loss:  0.6127928495407104\n",
      "epoch:  335  loss:  0.6125603318214417\n",
      "epoch:  336  loss:  0.6123279333114624\n",
      "epoch:  337  loss:  0.6120956540107727\n",
      "epoch:  338  loss:  0.6118634939193726\n",
      "epoch:  339  loss:  0.6116315126419067\n",
      "epoch:  340  loss:  0.6113995909690857\n",
      "epoch:  341  loss:  0.611167848110199\n",
      "epoch:  342  loss:  0.6109362840652466\n",
      "epoch:  343  loss:  0.6107048392295837\n",
      "epoch:  344  loss:  0.6104735136032104\n",
      "epoch:  345  loss:  0.6102423071861267\n",
      "epoch:  346  loss:  0.6100112199783325\n",
      "epoch:  347  loss:  0.6097803115844727\n",
      "epoch:  348  loss:  0.6095495223999023\n",
      "epoch:  349  loss:  0.6093187928199768\n",
      "epoch:  350  loss:  0.6090883016586304\n",
      "epoch:  351  loss:  0.6088578701019287\n",
      "epoch:  352  loss:  0.6086276173591614\n",
      "epoch:  353  loss:  0.6083974838256836\n",
      "epoch:  354  loss:  0.6081674695014954\n",
      "epoch:  355  loss:  0.6079376935958862\n",
      "epoch:  356  loss:  0.6077079772949219\n",
      "epoch:  357  loss:  0.6074783802032471\n",
      "epoch:  358  loss:  0.6072486639022827\n",
      "epoch:  359  loss:  0.6070188879966736\n",
      "epoch:  360  loss:  0.6067891716957092\n",
      "epoch:  361  loss:  0.6065596342086792\n",
      "epoch:  362  loss:  0.6063302159309387\n",
      "epoch:  363  loss:  0.6061009168624878\n",
      "epoch:  364  loss:  0.6058717370033264\n",
      "epoch:  365  loss:  0.6056427955627441\n",
      "epoch:  366  loss:  0.6054140329360962\n",
      "epoch:  367  loss:  0.6051855087280273\n",
      "epoch:  368  loss:  0.6049570441246033\n",
      "epoch:  369  loss:  0.6047287583351135\n",
      "epoch:  370  loss:  0.6045005321502686\n",
      "epoch:  371  loss:  0.6042725443840027\n",
      "epoch:  372  loss:  0.6040445566177368\n",
      "epoch:  373  loss:  0.60381680727005\n",
      "epoch:  374  loss:  0.6035890579223633\n",
      "epoch:  375  loss:  0.6033616065979004\n",
      "epoch:  376  loss:  0.6031341552734375\n",
      "epoch:  377  loss:  0.6029069423675537\n",
      "epoch:  378  loss:  0.6026797294616699\n",
      "epoch:  379  loss:  0.60245281457901\n",
      "epoch:  380  loss:  0.6022258996963501\n",
      "epoch:  381  loss:  0.6019991636276245\n",
      "epoch:  382  loss:  0.6017724871635437\n",
      "epoch:  383  loss:  0.601546049118042\n",
      "epoch:  384  loss:  0.6013197302818298\n",
      "epoch:  385  loss:  0.6010935306549072\n",
      "epoch:  386  loss:  0.6008674502372742\n",
      "epoch:  387  loss:  0.6006414890289307\n",
      "epoch:  388  loss:  0.6004157066345215\n",
      "epoch:  389  loss:  0.6001899838447571\n",
      "epoch:  390  loss:  0.599964439868927\n",
      "epoch:  391  loss:  0.5997390747070312\n",
      "epoch:  392  loss:  0.5995137691497803\n",
      "epoch:  393  loss:  0.5992885828018188\n",
      "epoch:  394  loss:  0.599063515663147\n",
      "epoch:  395  loss:  0.5988386869430542\n",
      "epoch:  396  loss:  0.5986139178276062\n",
      "epoch:  397  loss:  0.5983892679214478\n",
      "epoch:  398  loss:  0.5981648564338684\n",
      "epoch:  399  loss:  0.5979405641555786\n",
      "epoch:  400  loss:  0.5977165699005127\n",
      "epoch:  401  loss:  0.5974925756454468\n",
      "epoch:  402  loss:  0.5972687005996704\n",
      "epoch:  403  loss:  0.5970450043678284\n",
      "epoch:  404  loss:  0.5968215465545654\n",
      "epoch:  405  loss:  0.5965980291366577\n",
      "epoch:  406  loss:  0.5963746905326843\n",
      "epoch:  407  loss:  0.5961515307426453\n",
      "epoch:  408  loss:  0.5959285497665405\n",
      "epoch:  409  loss:  0.5957056283950806\n",
      "epoch:  410  loss:  0.5954827666282654\n",
      "epoch:  411  loss:  0.5952601432800293\n",
      "epoch:  412  loss:  0.5950376391410828\n",
      "epoch:  413  loss:  0.5948152542114258\n",
      "epoch:  414  loss:  0.5945929288864136\n",
      "epoch:  415  loss:  0.5943708419799805\n",
      "epoch:  416  loss:  0.5941488146781921\n",
      "epoch:  417  loss:  0.5939268469810486\n",
      "epoch:  418  loss:  0.5937051177024841\n",
      "epoch:  419  loss:  0.5934835076332092\n",
      "epoch:  420  loss:  0.5932620167732239\n",
      "epoch:  421  loss:  0.5930406451225281\n",
      "epoch:  422  loss:  0.592819333076477\n",
      "epoch:  423  loss:  0.5925982594490051\n",
      "epoch:  424  loss:  0.592377245426178\n",
      "epoch:  425  loss:  0.5921564102172852\n",
      "epoch:  426  loss:  0.5919356942176819\n",
      "epoch:  427  loss:  0.5917151570320129\n",
      "epoch:  428  loss:  0.5914946794509888\n",
      "epoch:  429  loss:  0.5912742614746094\n",
      "epoch:  430  loss:  0.5910540819168091\n",
      "epoch:  431  loss:  0.5908340215682983\n",
      "epoch:  432  loss:  0.5906140208244324\n",
      "epoch:  433  loss:  0.5903936624526978\n",
      "epoch:  434  loss:  0.5901736617088318\n",
      "epoch:  435  loss:  0.5899543166160583\n",
      "epoch:  436  loss:  0.5897351503372192\n",
      "epoch:  437  loss:  0.5895160436630249\n",
      "epoch:  438  loss:  0.5892971158027649\n",
      "epoch:  439  loss:  0.5890783667564392\n",
      "epoch:  440  loss:  0.5888598561286926\n",
      "epoch:  441  loss:  0.588641881942749\n",
      "epoch:  442  loss:  0.5884239673614502\n",
      "epoch:  443  loss:  0.5882062911987305\n",
      "epoch:  444  loss:  0.5879886150360107\n",
      "epoch:  445  loss:  0.5877710580825806\n",
      "epoch:  446  loss:  0.5875536799430847\n",
      "epoch:  447  loss:  0.5873364806175232\n",
      "epoch:  448  loss:  0.5871193408966064\n",
      "epoch:  449  loss:  0.586902379989624\n",
      "epoch:  450  loss:  0.5866852402687073\n",
      "epoch:  451  loss:  0.5864675045013428\n",
      "epoch:  452  loss:  0.5862498879432678\n",
      "epoch:  453  loss:  0.5860323309898376\n",
      "epoch:  454  loss:  0.585814893245697\n",
      "epoch:  455  loss:  0.5855976939201355\n",
      "epoch:  456  loss:  0.5853805541992188\n",
      "epoch:  457  loss:  0.5851637125015259\n",
      "epoch:  458  loss:  0.5849473476409912\n",
      "epoch:  459  loss:  0.5847311019897461\n",
      "epoch:  460  loss:  0.5845150351524353\n",
      "epoch:  461  loss:  0.5842990875244141\n",
      "epoch:  462  loss:  0.5840832591056824\n",
      "epoch:  463  loss:  0.583867609500885\n",
      "epoch:  464  loss:  0.5836520195007324\n",
      "epoch:  465  loss:  0.5834365487098694\n",
      "epoch:  466  loss:  0.5832212567329407\n",
      "epoch:  467  loss:  0.5830062627792358\n",
      "epoch:  468  loss:  0.5827916264533997\n",
      "epoch:  469  loss:  0.5825770497322083\n",
      "epoch:  470  loss:  0.582362711429596\n",
      "epoch:  471  loss:  0.5821484327316284\n",
      "epoch:  472  loss:  0.5819342732429504\n",
      "epoch:  473  loss:  0.5817202925682068\n",
      "epoch:  474  loss:  0.5815063714981079\n",
      "epoch:  475  loss:  0.5812926292419434\n",
      "epoch:  476  loss:  0.5810789465904236\n",
      "epoch:  477  loss:  0.5808655023574829\n",
      "epoch:  478  loss:  0.5806519985198975\n",
      "epoch:  479  loss:  0.5804386734962463\n",
      "epoch:  480  loss:  0.5802255868911743\n",
      "epoch:  481  loss:  0.5800125598907471\n",
      "epoch:  482  loss:  0.5797995924949646\n",
      "epoch:  483  loss:  0.5795868635177612\n",
      "epoch:  484  loss:  0.5793741941452026\n",
      "epoch:  485  loss:  0.5791616439819336\n",
      "epoch:  486  loss:  0.5789491534233093\n",
      "epoch:  487  loss:  0.5787369608879089\n",
      "epoch:  488  loss:  0.5785251259803772\n",
      "epoch:  489  loss:  0.578313410282135\n",
      "epoch:  490  loss:  0.5781017541885376\n",
      "epoch:  491  loss:  0.5778902769088745\n",
      "epoch:  492  loss:  0.577678918838501\n",
      "epoch:  493  loss:  0.5774677395820618\n",
      "epoch:  494  loss:  0.5772565007209778\n",
      "epoch:  495  loss:  0.5770455002784729\n",
      "epoch:  496  loss:  0.5768347382545471\n",
      "epoch:  497  loss:  0.5766238570213318\n",
      "epoch:  498  loss:  0.5764132738113403\n",
      "epoch:  499  loss:  0.5762027502059937\n",
      "epoch:  500  loss:  0.5759924650192261\n",
      "epoch:  501  loss:  0.5757822394371033\n",
      "epoch:  502  loss:  0.57557213306427\n",
      "epoch:  503  loss:  0.5753621459007263\n",
      "epoch:  504  loss:  0.5751522779464722\n",
      "epoch:  505  loss:  0.5749425888061523\n",
      "epoch:  506  loss:  0.5747328400611877\n",
      "epoch:  507  loss:  0.574523389339447\n",
      "epoch:  508  loss:  0.5743140578269958\n",
      "epoch:  509  loss:  0.5741047859191895\n",
      "epoch:  510  loss:  0.5738956332206726\n",
      "epoch:  511  loss:  0.5736865997314453\n",
      "epoch:  512  loss:  0.5734776854515076\n",
      "epoch:  513  loss:  0.5732690095901489\n",
      "epoch:  514  loss:  0.5730602741241455\n",
      "epoch:  515  loss:  0.5728517770767212\n",
      "epoch:  516  loss:  0.5726433992385864\n",
      "epoch:  517  loss:  0.5724350810050964\n",
      "epoch:  518  loss:  0.5722269415855408\n",
      "epoch:  519  loss:  0.5720189213752747\n",
      "epoch:  520  loss:  0.5718109607696533\n",
      "epoch:  521  loss:  0.5716031193733215\n",
      "epoch:  522  loss:  0.5713953971862793\n",
      "epoch:  523  loss:  0.5711878538131714\n",
      "epoch:  524  loss:  0.570980429649353\n",
      "epoch:  525  loss:  0.5707731246948242\n",
      "epoch:  526  loss:  0.570565938949585\n",
      "epoch:  527  loss:  0.5703588128089905\n",
      "epoch:  528  loss:  0.5701519250869751\n",
      "epoch:  529  loss:  0.5699450373649597\n",
      "epoch:  530  loss:  0.5697383284568787\n",
      "epoch:  531  loss:  0.5695317983627319\n",
      "epoch:  532  loss:  0.56932532787323\n",
      "epoch:  533  loss:  0.5691189765930176\n",
      "epoch:  534  loss:  0.56891268491745\n",
      "epoch:  535  loss:  0.5687066316604614\n",
      "epoch:  536  loss:  0.5685006380081177\n",
      "epoch:  537  loss:  0.5682947635650635\n",
      "epoch:  538  loss:  0.568088948726654\n",
      "epoch:  539  loss:  0.5678833723068237\n",
      "epoch:  540  loss:  0.5676777958869934\n",
      "epoch:  541  loss:  0.5674723982810974\n",
      "epoch:  542  loss:  0.567267119884491\n",
      "epoch:  543  loss:  0.5670619606971741\n",
      "epoch:  544  loss:  0.5668569207191467\n",
      "epoch:  545  loss:  0.5666521191596985\n",
      "epoch:  546  loss:  0.5664472579956055\n",
      "epoch:  547  loss:  0.566242516040802\n",
      "epoch:  548  loss:  0.5660379528999329\n",
      "epoch:  549  loss:  0.5658335089683533\n",
      "epoch:  550  loss:  0.5656291842460632\n",
      "epoch:  551  loss:  0.5654249787330627\n",
      "epoch:  552  loss:  0.565220832824707\n",
      "epoch:  553  loss:  0.5650168657302856\n",
      "epoch:  554  loss:  0.5648130178451538\n",
      "epoch:  555  loss:  0.5646092295646667\n",
      "epoch:  556  loss:  0.564405620098114\n",
      "epoch:  557  loss:  0.5642021298408508\n",
      "epoch:  558  loss:  0.5639986991882324\n",
      "epoch:  559  loss:  0.5637954473495483\n",
      "epoch:  560  loss:  0.563592255115509\n",
      "epoch:  561  loss:  0.563389241695404\n",
      "epoch:  562  loss:  0.5631863474845886\n",
      "epoch:  563  loss:  0.5629835724830627\n",
      "epoch:  564  loss:  0.5627808570861816\n",
      "epoch:  565  loss:  0.5625782608985901\n",
      "epoch:  566  loss:  0.5623757839202881\n",
      "epoch:  567  loss:  0.5621734857559204\n",
      "epoch:  568  loss:  0.5619712471961975\n",
      "epoch:  569  loss:  0.5617691874504089\n",
      "epoch:  570  loss:  0.5615671873092651\n",
      "epoch:  571  loss:  0.5613653063774109\n",
      "epoch:  572  loss:  0.5611635446548462\n",
      "epoch:  573  loss:  0.5609619617462158\n",
      "epoch:  574  loss:  0.5607603788375854\n",
      "epoch:  575  loss:  0.5605589151382446\n",
      "epoch:  576  loss:  0.5603571534156799\n",
      "epoch:  577  loss:  0.5601553916931152\n",
      "epoch:  578  loss:  0.5599538087844849\n",
      "epoch:  579  loss:  0.559752345085144\n",
      "epoch:  580  loss:  0.5595508813858032\n",
      "epoch:  581  loss:  0.5593497157096863\n",
      "epoch:  582  loss:  0.5591485500335693\n",
      "epoch:  583  loss:  0.5589475035667419\n",
      "epoch:  584  loss:  0.5587466359138489\n",
      "epoch:  585  loss:  0.5585458278656006\n",
      "epoch:  586  loss:  0.5583451986312866\n",
      "epoch:  587  loss:  0.5581445693969727\n",
      "epoch:  588  loss:  0.557944118976593\n",
      "epoch:  589  loss:  0.5577438473701477\n",
      "epoch:  590  loss:  0.5575436949729919\n",
      "epoch:  591  loss:  0.5573435425758362\n",
      "epoch:  592  loss:  0.55714350938797\n",
      "epoch:  593  loss:  0.5569437146186829\n",
      "epoch:  594  loss:  0.5567439198493958\n",
      "epoch:  595  loss:  0.5565443634986877\n",
      "epoch:  596  loss:  0.5563448071479797\n",
      "epoch:  597  loss:  0.556145429611206\n",
      "epoch:  598  loss:  0.5559461712837219\n",
      "epoch:  599  loss:  0.5557469129562378\n",
      "epoch:  600  loss:  0.5555478930473328\n",
      "epoch:  601  loss:  0.5553489327430725\n",
      "epoch:  602  loss:  0.555150032043457\n",
      "epoch:  603  loss:  0.5549513697624207\n",
      "epoch:  604  loss:  0.5547527074813843\n",
      "epoch:  605  loss:  0.5545542240142822\n",
      "epoch:  606  loss:  0.554355800151825\n",
      "epoch:  607  loss:  0.5541574954986572\n",
      "epoch:  608  loss:  0.5539593696594238\n",
      "epoch:  609  loss:  0.55376136302948\n",
      "epoch:  610  loss:  0.5535633563995361\n",
      "epoch:  611  loss:  0.5533655881881714\n",
      "epoch:  612  loss:  0.5531678795814514\n",
      "epoch:  613  loss:  0.552970290184021\n",
      "epoch:  614  loss:  0.5527727603912354\n",
      "epoch:  615  loss:  0.5525754690170288\n",
      "epoch:  616  loss:  0.5523780584335327\n",
      "epoch:  617  loss:  0.5521803498268127\n",
      "epoch:  618  loss:  0.5519827604293823\n",
      "epoch:  619  loss:  0.5517851710319519\n",
      "epoch:  620  loss:  0.5515877604484558\n",
      "epoch:  621  loss:  0.5513904690742493\n",
      "epoch:  622  loss:  0.5511932969093323\n",
      "epoch:  623  loss:  0.5509962439537048\n",
      "epoch:  624  loss:  0.5507992506027222\n",
      "epoch:  625  loss:  0.5506024360656738\n",
      "epoch:  626  loss:  0.5504056811332703\n",
      "epoch:  627  loss:  0.5502090454101562\n",
      "epoch:  628  loss:  0.5500125288963318\n",
      "epoch:  629  loss:  0.5498161911964417\n",
      "epoch:  630  loss:  0.5496198534965515\n",
      "epoch:  631  loss:  0.5494236946105957\n",
      "epoch:  632  loss:  0.5492276549339294\n",
      "epoch:  633  loss:  0.549031674861908\n",
      "epoch:  634  loss:  0.5488358736038208\n",
      "epoch:  635  loss:  0.5486401915550232\n",
      "epoch:  636  loss:  0.5484445095062256\n",
      "epoch:  637  loss:  0.5482490062713623\n",
      "epoch:  638  loss:  0.5480536818504333\n",
      "epoch:  639  loss:  0.5478584170341492\n",
      "epoch:  640  loss:  0.5476632714271545\n",
      "epoch:  641  loss:  0.5474681854248047\n",
      "epoch:  642  loss:  0.5472733378410339\n",
      "epoch:  643  loss:  0.5470784902572632\n",
      "epoch:  644  loss:  0.546883761882782\n",
      "epoch:  645  loss:  0.5466892123222351\n",
      "epoch:  646  loss:  0.546494722366333\n",
      "epoch:  647  loss:  0.5463003516197205\n",
      "epoch:  648  loss:  0.5461061596870422\n",
      "epoch:  649  loss:  0.545911967754364\n",
      "epoch:  650  loss:  0.5457180142402649\n",
      "epoch:  651  loss:  0.545524001121521\n",
      "epoch:  652  loss:  0.5453302264213562\n",
      "epoch:  653  loss:  0.545136570930481\n",
      "epoch:  654  loss:  0.5449429750442505\n",
      "epoch:  655  loss:  0.5447495579719543\n",
      "epoch:  656  loss:  0.5445561408996582\n",
      "epoch:  657  loss:  0.5443629622459412\n",
      "epoch:  658  loss:  0.5441697835922241\n",
      "epoch:  659  loss:  0.5439767241477966\n",
      "epoch:  660  loss:  0.5437838435173035\n",
      "epoch:  661  loss:  0.5435911417007446\n",
      "epoch:  662  loss:  0.5433984398841858\n",
      "epoch:  663  loss:  0.5432057976722717\n",
      "epoch:  664  loss:  0.543013334274292\n",
      "epoch:  665  loss:  0.5428210496902466\n",
      "epoch:  666  loss:  0.5426287651062012\n",
      "epoch:  667  loss:  0.5424366593360901\n",
      "epoch:  668  loss:  0.5422446131706238\n",
      "epoch:  669  loss:  0.5420527458190918\n",
      "epoch:  670  loss:  0.5418609976768494\n",
      "epoch:  671  loss:  0.5416693091392517\n",
      "epoch:  672  loss:  0.5414777398109436\n",
      "epoch:  673  loss:  0.541286289691925\n",
      "epoch:  674  loss:  0.5410948991775513\n",
      "epoch:  675  loss:  0.5409036874771118\n",
      "epoch:  676  loss:  0.5407125353813171\n",
      "epoch:  677  loss:  0.5405215620994568\n",
      "epoch:  678  loss:  0.5403308272361755\n",
      "epoch:  679  loss:  0.5401403307914734\n",
      "epoch:  680  loss:  0.5399498343467712\n",
      "epoch:  681  loss:  0.5397594571113586\n",
      "epoch:  682  loss:  0.5395692586898804\n",
      "epoch:  683  loss:  0.5393791198730469\n",
      "epoch:  684  loss:  0.5391891002655029\n",
      "epoch:  685  loss:  0.5389992594718933\n",
      "epoch:  686  loss:  0.5388095378875732\n",
      "epoch:  687  loss:  0.5386198163032532\n",
      "epoch:  688  loss:  0.5384302735328674\n",
      "epoch:  689  loss:  0.5382408499717712\n",
      "epoch:  690  loss:  0.5380514860153198\n",
      "epoch:  691  loss:  0.5378623008728027\n",
      "epoch:  692  loss:  0.5376731753349304\n",
      "epoch:  693  loss:  0.5374841690063477\n",
      "epoch:  694  loss:  0.5372952818870544\n",
      "epoch:  695  loss:  0.537106454372406\n",
      "epoch:  696  loss:  0.5369178056716919\n",
      "epoch:  697  loss:  0.5367292165756226\n",
      "epoch:  698  loss:  0.5365407466888428\n",
      "epoch:  699  loss:  0.5363523960113525\n",
      "epoch:  700  loss:  0.5361641645431519\n",
      "epoch:  701  loss:  0.535975992679596\n",
      "epoch:  702  loss:  0.5357879996299744\n",
      "epoch:  703  loss:  0.5356000661849976\n",
      "epoch:  704  loss:  0.5354122519493103\n",
      "epoch:  705  loss:  0.5352246165275574\n",
      "epoch:  706  loss:  0.5350370407104492\n",
      "epoch:  707  loss:  0.5348495244979858\n",
      "epoch:  708  loss:  0.534662127494812\n",
      "epoch:  709  loss:  0.5344748497009277\n",
      "epoch:  710  loss:  0.534287691116333\n",
      "epoch:  711  loss:  0.5341006517410278\n",
      "epoch:  712  loss:  0.5339137315750122\n",
      "epoch:  713  loss:  0.5337269306182861\n",
      "epoch:  714  loss:  0.5335401296615601\n",
      "epoch:  715  loss:  0.5333535671234131\n",
      "epoch:  716  loss:  0.5331670641899109\n",
      "epoch:  717  loss:  0.5329806208610535\n",
      "epoch:  718  loss:  0.5327943563461304\n",
      "epoch:  719  loss:  0.532608151435852\n",
      "epoch:  720  loss:  0.5324220061302185\n",
      "epoch:  721  loss:  0.5322353839874268\n",
      "epoch:  722  loss:  0.5320489406585693\n",
      "epoch:  723  loss:  0.5318625569343567\n",
      "epoch:  724  loss:  0.5316762328147888\n",
      "epoch:  725  loss:  0.5314900875091553\n",
      "epoch:  726  loss:  0.5313040018081665\n",
      "epoch:  727  loss:  0.5311180353164673\n",
      "epoch:  728  loss:  0.5309321880340576\n",
      "epoch:  729  loss:  0.5307465195655823\n",
      "epoch:  730  loss:  0.5305609107017517\n",
      "epoch:  731  loss:  0.5303753614425659\n",
      "epoch:  732  loss:  0.5301899313926697\n",
      "epoch:  733  loss:  0.5300043821334839\n",
      "epoch:  734  loss:  0.5298186540603638\n",
      "epoch:  735  loss:  0.5296329259872437\n",
      "epoch:  736  loss:  0.5294472575187683\n",
      "epoch:  737  loss:  0.5292617678642273\n",
      "epoch:  738  loss:  0.5290763974189758\n",
      "epoch:  739  loss:  0.5288911461830139\n",
      "epoch:  740  loss:  0.528705894947052\n",
      "epoch:  741  loss:  0.5285208225250244\n",
      "epoch:  742  loss:  0.5283358693122864\n",
      "epoch:  743  loss:  0.5281510353088379\n",
      "epoch:  744  loss:  0.527966320514679\n",
      "epoch:  745  loss:  0.5277816653251648\n",
      "epoch:  746  loss:  0.5275970697402954\n",
      "epoch:  747  loss:  0.5274127125740051\n",
      "epoch:  748  loss:  0.5272283554077148\n",
      "epoch:  749  loss:  0.5270441770553589\n",
      "epoch:  750  loss:  0.5268600583076477\n",
      "epoch:  751  loss:  0.5266759991645813\n",
      "epoch:  752  loss:  0.5264921188354492\n",
      "epoch:  753  loss:  0.5263083577156067\n",
      "epoch:  754  loss:  0.5261247158050537\n",
      "epoch:  755  loss:  0.5259411334991455\n",
      "epoch:  756  loss:  0.5257576107978821\n",
      "epoch:  757  loss:  0.525574266910553\n",
      "epoch:  758  loss:  0.5253911018371582\n",
      "epoch:  759  loss:  0.5252078771591187\n",
      "epoch:  760  loss:  0.5250248312950134\n",
      "epoch:  761  loss:  0.5248419046401978\n",
      "epoch:  762  loss:  0.5246590971946716\n",
      "epoch:  763  loss:  0.5244763493537903\n",
      "epoch:  764  loss:  0.5242937803268433\n",
      "epoch:  765  loss:  0.5241112112998962\n",
      "epoch:  766  loss:  0.5239288210868835\n",
      "epoch:  767  loss:  0.5237465500831604\n",
      "epoch:  768  loss:  0.523564338684082\n",
      "epoch:  769  loss:  0.523382306098938\n",
      "epoch:  770  loss:  0.523200273513794\n",
      "epoch:  771  loss:  0.5230184197425842\n",
      "epoch:  772  loss:  0.5228366851806641\n",
      "epoch:  773  loss:  0.5226549506187439\n",
      "epoch:  774  loss:  0.5224734544754028\n",
      "epoch:  775  loss:  0.5222919583320618\n",
      "epoch:  776  loss:  0.522110641002655\n",
      "epoch:  777  loss:  0.5219293832778931\n",
      "epoch:  778  loss:  0.5217482447624207\n",
      "epoch:  779  loss:  0.5215672254562378\n",
      "epoch:  780  loss:  0.5213863253593445\n",
      "epoch:  781  loss:  0.521205484867096\n",
      "epoch:  782  loss:  0.5210248231887817\n",
      "epoch:  783  loss:  0.5208441615104675\n",
      "epoch:  784  loss:  0.5206636786460876\n",
      "epoch:  785  loss:  0.5204832553863525\n",
      "epoch:  786  loss:  0.520302951335907\n",
      "epoch:  787  loss:  0.5201228857040405\n",
      "epoch:  788  loss:  0.5199428200721741\n",
      "epoch:  789  loss:  0.5197629332542419\n",
      "epoch:  790  loss:  0.5195831060409546\n",
      "epoch:  791  loss:  0.5194033980369568\n",
      "epoch:  792  loss:  0.5192237496376038\n",
      "epoch:  793  loss:  0.5190442204475403\n",
      "epoch:  794  loss:  0.5188648700714111\n",
      "epoch:  795  loss:  0.5186855792999268\n",
      "epoch:  796  loss:  0.5185063481330872\n",
      "epoch:  797  loss:  0.5183272957801819\n",
      "epoch:  798  loss:  0.5181482434272766\n",
      "epoch:  799  loss:  0.5179694294929504\n",
      "epoch:  800  loss:  0.5177907347679138\n",
      "epoch:  801  loss:  0.5176120400428772\n",
      "epoch:  802  loss:  0.5174334645271301\n",
      "epoch:  803  loss:  0.5172549486160278\n",
      "epoch:  804  loss:  0.5170766711235046\n",
      "epoch:  805  loss:  0.5168983936309814\n",
      "epoch:  806  loss:  0.5167202949523926\n",
      "epoch:  807  loss:  0.5165421962738037\n",
      "epoch:  808  loss:  0.5163642764091492\n",
      "epoch:  809  loss:  0.5161864161491394\n",
      "epoch:  810  loss:  0.5160086750984192\n",
      "epoch:  811  loss:  0.5158310532569885\n",
      "epoch:  812  loss:  0.5156535506248474\n",
      "epoch:  813  loss:  0.5154761075973511\n",
      "epoch:  814  loss:  0.5152987837791443\n",
      "epoch:  815  loss:  0.515121579170227\n",
      "epoch:  816  loss:  0.5149444937705994\n",
      "epoch:  817  loss:  0.5147674679756165\n",
      "epoch:  818  loss:  0.5145906209945679\n",
      "epoch:  819  loss:  0.5144137740135193\n",
      "epoch:  820  loss:  0.514237105846405\n",
      "epoch:  821  loss:  0.5140604972839355\n",
      "epoch:  822  loss:  0.5138840079307556\n",
      "epoch:  823  loss:  0.5137075781822205\n",
      "epoch:  824  loss:  0.5135313272476196\n",
      "epoch:  825  loss:  0.5133551359176636\n",
      "epoch:  826  loss:  0.5131790041923523\n",
      "epoch:  827  loss:  0.5130030512809753\n",
      "epoch:  828  loss:  0.5128271579742432\n",
      "epoch:  829  loss:  0.5126513838768005\n",
      "epoch:  830  loss:  0.5124757289886475\n",
      "epoch:  831  loss:  0.5123001933097839\n",
      "epoch:  832  loss:  0.5121247172355652\n",
      "epoch:  833  loss:  0.5119493007659912\n",
      "epoch:  834  loss:  0.5117740631103516\n",
      "epoch:  835  loss:  0.5115989446640015\n",
      "epoch:  836  loss:  0.5114239454269409\n",
      "epoch:  837  loss:  0.5112489461898804\n",
      "epoch:  838  loss:  0.5110740661621094\n",
      "epoch:  839  loss:  0.5108993053436279\n",
      "epoch:  840  loss:  0.510724663734436\n",
      "epoch:  841  loss:  0.5105500817298889\n",
      "epoch:  842  loss:  0.5103756785392761\n",
      "epoch:  843  loss:  0.5102012753486633\n",
      "epoch:  844  loss:  0.5100271105766296\n",
      "epoch:  845  loss:  0.509852945804596\n",
      "epoch:  846  loss:  0.5096789002418518\n",
      "epoch:  847  loss:  0.5095049142837524\n",
      "epoch:  848  loss:  0.5093311071395874\n",
      "epoch:  849  loss:  0.5091574788093567\n",
      "epoch:  850  loss:  0.5089837312698364\n",
      "epoch:  851  loss:  0.5088102221488953\n",
      "epoch:  852  loss:  0.5086367726325989\n",
      "epoch:  853  loss:  0.508463442325592\n",
      "epoch:  854  loss:  0.5082902312278748\n",
      "epoch:  855  loss:  0.5081170797348022\n",
      "epoch:  856  loss:  0.5079440474510193\n",
      "epoch:  857  loss:  0.5077711343765259\n",
      "epoch:  858  loss:  0.5075982809066772\n",
      "epoch:  859  loss:  0.5074256062507629\n",
      "epoch:  860  loss:  0.5072529315948486\n",
      "epoch:  861  loss:  0.5070804357528687\n",
      "epoch:  862  loss:  0.5069080591201782\n",
      "epoch:  863  loss:  0.5067356824874878\n",
      "epoch:  864  loss:  0.5065634846687317\n",
      "epoch:  865  loss:  0.5063913464546204\n",
      "epoch:  866  loss:  0.5062193274497986\n",
      "epoch:  867  loss:  0.5060473680496216\n",
      "epoch:  868  loss:  0.5058755874633789\n",
      "epoch:  869  loss:  0.5057039260864258\n",
      "epoch:  870  loss:  0.5055323243141174\n",
      "epoch:  871  loss:  0.505361020565033\n",
      "epoch:  872  loss:  0.5051898956298828\n",
      "epoch:  873  loss:  0.5050188302993774\n",
      "epoch:  874  loss:  0.5048478245735168\n",
      "epoch:  875  loss:  0.5046769976615906\n",
      "epoch:  876  loss:  0.5045062303543091\n",
      "epoch:  877  loss:  0.5043355226516724\n",
      "epoch:  878  loss:  0.50416499376297\n",
      "epoch:  879  loss:  0.5039945244789124\n",
      "epoch:  880  loss:  0.5038241744041443\n",
      "epoch:  881  loss:  0.503653883934021\n",
      "epoch:  882  loss:  0.5034837126731873\n",
      "epoch:  883  loss:  0.5033136606216431\n",
      "epoch:  884  loss:  0.5031437277793884\n",
      "epoch:  885  loss:  0.5029737949371338\n",
      "epoch:  886  loss:  0.5028040409088135\n",
      "epoch:  887  loss:  0.5026344060897827\n",
      "epoch:  888  loss:  0.5024648308753967\n",
      "epoch:  889  loss:  0.5022953152656555\n",
      "epoch:  890  loss:  0.5021259784698486\n",
      "epoch:  891  loss:  0.5019566416740417\n",
      "epoch:  892  loss:  0.501787543296814\n",
      "epoch:  893  loss:  0.5016184449195862\n",
      "epoch:  894  loss:  0.5014495253562927\n",
      "epoch:  895  loss:  0.5012806057929993\n",
      "epoch:  896  loss:  0.5011118650436401\n",
      "epoch:  897  loss:  0.5009431838989258\n",
      "epoch:  898  loss:  0.5007745623588562\n",
      "epoch:  899  loss:  0.500606119632721\n",
      "epoch:  900  loss:  0.5004377365112305\n",
      "epoch:  901  loss:  0.5002694725990295\n",
      "epoch:  902  loss:  0.5001012086868286\n",
      "epoch:  903  loss:  0.4999331533908844\n",
      "epoch:  904  loss:  0.49976521730422974\n",
      "epoch:  905  loss:  0.4995972812175751\n",
      "epoch:  906  loss:  0.49942949414253235\n",
      "epoch:  907  loss:  0.4992617964744568\n",
      "epoch:  908  loss:  0.499094158411026\n",
      "epoch:  909  loss:  0.49892666935920715\n",
      "epoch:  910  loss:  0.4987594485282898\n",
      "epoch:  911  loss:  0.498592346906662\n",
      "epoch:  912  loss:  0.49842533469200134\n",
      "epoch:  913  loss:  0.4982583820819855\n",
      "epoch:  914  loss:  0.49809157848358154\n",
      "epoch:  915  loss:  0.4979248642921448\n",
      "epoch:  916  loss:  0.49775823950767517\n",
      "epoch:  917  loss:  0.49759167432785034\n",
      "epoch:  918  loss:  0.49742525815963745\n",
      "epoch:  919  loss:  0.49725890159606934\n",
      "epoch:  920  loss:  0.49709266424179077\n",
      "epoch:  921  loss:  0.49692651629447937\n",
      "epoch:  922  loss:  0.49676045775413513\n",
      "epoch:  923  loss:  0.49659454822540283\n",
      "epoch:  924  loss:  0.4964286684989929\n",
      "epoch:  925  loss:  0.49626293778419495\n",
      "epoch:  926  loss:  0.49609726667404175\n",
      "epoch:  927  loss:  0.4959317445755005\n",
      "epoch:  928  loss:  0.49576616287231445\n",
      "epoch:  929  loss:  0.4956008493900299\n",
      "epoch:  930  loss:  0.49543553590774536\n",
      "epoch:  931  loss:  0.49527043104171753\n",
      "epoch:  932  loss:  0.4951052963733673\n",
      "epoch:  933  loss:  0.4949403405189514\n",
      "epoch:  934  loss:  0.4947755038738251\n",
      "epoch:  935  loss:  0.49461087584495544\n",
      "epoch:  936  loss:  0.494446337223053\n",
      "epoch:  937  loss:  0.4942818880081177\n",
      "epoch:  938  loss:  0.4941175580024719\n",
      "epoch:  939  loss:  0.49395328760147095\n",
      "epoch:  940  loss:  0.4937891364097595\n",
      "epoch:  941  loss:  0.49362507462501526\n",
      "epoch:  942  loss:  0.49346113204956055\n",
      "epoch:  943  loss:  0.4932972192764282\n",
      "epoch:  944  loss:  0.4931333363056183\n",
      "epoch:  945  loss:  0.4929690361022949\n",
      "epoch:  946  loss:  0.4928048551082611\n",
      "epoch:  947  loss:  0.49264079332351685\n",
      "epoch:  948  loss:  0.49247679114341736\n",
      "epoch:  949  loss:  0.49231287837028503\n",
      "epoch:  950  loss:  0.49214908480644226\n",
      "epoch:  951  loss:  0.49198538064956665\n",
      "epoch:  952  loss:  0.491821825504303\n",
      "epoch:  953  loss:  0.4916583001613617\n",
      "epoch:  954  loss:  0.49149489402770996\n",
      "epoch:  955  loss:  0.4913315773010254\n",
      "epoch:  956  loss:  0.491168349981308\n",
      "epoch:  957  loss:  0.49100518226623535\n",
      "epoch:  958  loss:  0.49084219336509705\n",
      "epoch:  959  loss:  0.4906792938709259\n",
      "epoch:  960  loss:  0.49051645398139954\n",
      "epoch:  961  loss:  0.49035367369651794\n",
      "epoch:  962  loss:  0.4901910126209259\n",
      "epoch:  963  loss:  0.490028440952301\n",
      "epoch:  964  loss:  0.48986607789993286\n",
      "epoch:  965  loss:  0.4897036552429199\n",
      "epoch:  966  loss:  0.4895414412021637\n",
      "epoch:  967  loss:  0.48937925696372986\n",
      "epoch:  968  loss:  0.4892171621322632\n",
      "epoch:  969  loss:  0.48905518651008606\n",
      "epoch:  970  loss:  0.4888933300971985\n",
      "epoch:  971  loss:  0.4887315630912781\n",
      "epoch:  972  loss:  0.48856985569000244\n",
      "epoch:  973  loss:  0.48840823769569397\n",
      "epoch:  974  loss:  0.48824670910835266\n",
      "epoch:  975  loss:  0.4880853593349457\n",
      "epoch:  976  loss:  0.4879240393638611\n",
      "epoch:  977  loss:  0.48776283860206604\n",
      "epoch:  978  loss:  0.487601637840271\n",
      "epoch:  979  loss:  0.48744064569473267\n",
      "epoch:  980  loss:  0.4872797131538391\n",
      "epoch:  981  loss:  0.4871188700199127\n",
      "epoch:  982  loss:  0.4869581460952759\n",
      "epoch:  983  loss:  0.4867974817752838\n",
      "epoch:  984  loss:  0.4866369366645813\n",
      "epoch:  985  loss:  0.48647642135620117\n",
      "epoch:  986  loss:  0.48631611466407776\n",
      "epoch:  987  loss:  0.48615583777427673\n",
      "epoch:  988  loss:  0.48599565029144287\n",
      "epoch:  989  loss:  0.48583558201789856\n",
      "epoch:  990  loss:  0.485675573348999\n",
      "epoch:  991  loss:  0.48551565408706665\n",
      "epoch:  992  loss:  0.48535582423210144\n",
      "epoch:  993  loss:  0.48519614338874817\n",
      "epoch:  994  loss:  0.4850364923477173\n",
      "epoch:  995  loss:  0.4848763048648834\n",
      "epoch:  996  loss:  0.48471617698669434\n",
      "epoch:  997  loss:  0.4845561981201172\n",
      "epoch:  998  loss:  0.4843962788581848\n",
      "epoch:  999  loss:  0.4842364192008972\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    y_pred_3 = model_lr_1(X)\n",
    "    loss = metrics_name_2(y_pred_3, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    Optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    Optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "baf65f5e-439d-4dec-867d-9cc2be91f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "01ad8d80-aa5b-4707-8b93-48ce15f05d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1(model_lr_1, loss_fn, optimizer):\n",
    "    \"\"\"function_1 train_1\"\"\"\n",
    "    size = len(X_train_tensor)\n",
    "    model_lr_1.train()\n",
    "    for batch_size_lr_1 in range(1000):\n",
    "        y_pred_4 = model_lr_1(X)\n",
    "        loss = loss_fn(y_pred_4, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if BATCH_SIZE_LR_1 % 16 == 0:\n",
    "            loss_3 = loss.item(), BATCH_SIZE_LR * len(X)\n",
    "            print(f'loss: {loss_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "553bf6dd-fc34-4d2b-856c-f013aac95109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"function_1 train_1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e48e01c4-8f06-4eb8-90da-32fbc32222c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1(model_lr_1, loss_fn):\n",
    "    \"\"\"function_1 test_1\"\"\"\n",
    "    size = len(X_train_tensor)\n",
    "    num_batches = size\n",
    "    model_lr_1.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_size_lr_1 in range(1000):\n",
    "            y_pred_5 = model_lr_1(X)\n",
    "            test_loss += loss_fn(y_pred_5, y).item()\n",
    "            test_loss /= num_batches\n",
    "            print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4bd6e01f-1b9d-4830-9fdf-251e8174ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"function_1 test_1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d824f07f-395b-4172-966e-0d8758539b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1235]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model_lr_1(X_test_tensor[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c645e8ab-7172-468b-8da4-ada061d69776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_tensor[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f8ceeb44-84bf-426b-aeb5-d84264465a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_lr_1, \"lr_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f3f02ed4-f570-4906-9cb5-a94df929c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadff9b-efeb-425c-8425-eaefc0364a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
